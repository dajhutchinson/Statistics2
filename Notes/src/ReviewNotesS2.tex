\documentclass[11pt,a4paper]{article}

\usepackage[margin=1in, paperwidth=8.3in, paperheight=11.7in]{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{changepage} 

\begin{document}

\pagestyle{fancy}
\setlength\parindent{0pt}
\allowdisplaybreaks

\renewcommand{\headrulewidth}{0pt}

% Cover page title
\title{Statistics 2 - Reviewed Notes}
\author{Dom Hutchinson}
\date{\today}
\maketitle

% Header
\fancyhead[L]{Dom Hutchinson}
\fancyhead[C]{Statistics 2 - Reviewed Notes}
\fancyhead[R]{\today}

% Default enumerate labeling
\setlist[enumerate,1]{label={\roman*)}}

% Counters
\newcounter{definition}[section]
\newcounter{example}[section]
\newcounter{notation}[section]
\newcounter{proposition}[section]
\newcounter{proof}[section]
\newcounter{remark}[section]
\newcounter{theorem}[section]

% commands
\newcommand{\dotprod}[0]{\boldsymbol{\cdot}}
\newcommand{\cosech}[0]{\mathrm{cosech}\ }
\newcommand{\cosec}[0]{\mathrm{cosec}\ }
\newcommand{\sech}[0]{\mathrm{sech}\ }
\newcommand{\prob}[0]{\mathbb{P}}
\newcommand{\nats}[0]{\mathbb{N}}
\newcommand{\cov}[0]{\mathrm{Cov}}
\newcommand{\var}[0]{\mathrm{Var}}
\newcommand{\expect}[0]{\mathbb{E}}
\newcommand{\reals}[0]{\mathbb{R}}
\newcommand{\integers}[0]{\mathbb{Z}}
\newcommand{\indicator}[0]{\mathds{1}}
\newcommand{\nb}[0]{\textit{N.B.} }
\newcommand{\ie}[0]{\textit{i.e.} }
\newcommand{\eg}[0]{\textit{e.g.} }
\newcommand{\X}[0]{\textbf{X}}
\newcommand{\x}[0]{\textbf{x}}
\newcommand{\iid}[0]{\overset{\text{iid}}{\sim}}
\newcommand{\proved}[0]{$\hfill\square$\\}

\newcommand{\definition}[1]{\stepcounter{definition} \textbf{Definition \arabic{section}.\arabic{definition}\ - }\textit{#1}\\}
\newcommand{\definitionn}[1]{\stepcounter{definition} \textbf{Definition \arabic{section}.\arabic{definition}\ - }\textit{#1}}
\newcommand{\proof}[1]{\stepcounter{proof} \textbf{Proof \arabic{section}.\arabic{proof}\ - }\textit{#1}\\}
\newcommand{\prooff}[1]{\stepcounter{proof} \textbf{Proof \arabic{section}.\arabic{proof}\ - }\textit{#1}}
\newcommand{\example}[1]{\stepcounter{example} \textbf{Example \arabic{section}.\arabic{example}\ - }\textit{#1}\\}
\newcommand{\examplee}[1]{\stepcounter{example} \textbf{Example \arabic{section}.\arabic{example}\ - }\textit{#1}}
\newcommand{\notation}[1]{\stepcounter{notation} \textbf{Notation \arabic{section}.\arabic{notation}\ - }\textit{#1}\\}
\newcommand{\notationn}[1]{\stepcounter{notation} \textbf{Notation \arabic{section}.\arabic{notation}\ - }\textit{#1}}
\newcommand{\proposition}[1]{\stepcounter{proposition} \textbf{Proposition \arabic{section}.\arabic{proposition}\ - }\textit{#1}\\}
\newcommand{\propositionn}[1]{\stepcounter{proposition} \textbf{Proposition \arabic{section}.\arabic{proposition}\ - }\textit{#1}}
\newcommand{\remark}[1]{\stepcounter{remark} \textbf{Remark \arabic{section}.\arabic{remark}\ - }\textit{#1}\\}
\newcommand{\remarkk}[1]{\stepcounter{remark} \textbf{Remark \arabic{section}.\arabic{remark}\ - }\textit{#1}}
\newcommand{\theorem}[1]{\stepcounter{theorem} \textbf{Theorem \arabic{section}.\arabic{theorem}\ - }\textit{#1}\\}
\newcommand{\theoremm}[1]{\stepcounter{theorem} \textbf{Theorem \arabic{section}.\arabic{theorem}\ - }\textit{#1}}

\tableofcontents

% Start of content
\newpage

\section{General}

\subsection{Definitions}

\definition{Probability Space, $(\Omega,\mathcal{F},\prob)$}
A \textit{Probabiltiy Space} is a mathematicla construct for modelling the real world. A \textit{Probabilitiy Space} has three elements
\begin{enumerate}
	\item $\Omega$, Sample space;
	\item $\mathcal{F}$, Set of events; and,
	\item $\prob$, Probability Measure
\end{enumerate}
and must filfil the following criteria
\begin{enumerate}
	\item $\Omega\in\mathcal{F}$;
	\item $\forall\ A\in\mathcal{D}\implies A^c\in\mathcal{F}$;
	\item $\forall\ A_0,\dots,A_n\in\mathcal{F}\implies\left(\bigcup\limits_{i=0}^nA_i\right)\in\mathcal{F}$;
	\item $\prob(\Omega)=1$; and,
	\item $\prob\left(\bigcup\limits_{i=0}^n\right)=\sum\limits_{i=0}^n\prob(A_i)$ for any $n$ disjoint $A_0,\dots,A_n$.
\end{enumerate}

\definition{Random Variable}
A \textit{Random Variable} is a function which maps an event in the sample space to a value. $X$ is a random variable if it satisfies the signature
$$X:\Omega\to\reals$$

\definition{Parametric Models}
\textit{Parametric Models} are the class of statistical distributions whose probability mass/density function take parameters. These parameters represent values of interest in the population, such as mean or variance. We generally do not know these values so we estimate them from samples.\\

\definition{Quantity of Interest}
When analysing distributions it often helps to define \textit{Quantities of Interest} about the distributions (\eg Mean). These are defined as functions in terms of the parameters $\tau(\theta)$. We estimate \textit{Quantities of Interest} by passing estimated values of the parameters $\hat{\tau}=\tau(\hat{\theta})$.\\

\definition{Frequentist Approach}
The \textit{Frequentist Approach} to probability is an interpretation of probability where \textit{Probability} refers to the limiting relative frequencies of events. \textit{Probabilities} are objective properties of the world.
$$\prob(X=x)=\lim_{n\to\infty}\frac{k}{n}$$
where $k$ is the number of times $x$ is observed in $n$ samples.\\
\nb Most of this module follows this approach.\\

\definition{Bayesian Approach}
The \textit{Frequentist Approach} to probability is an interpretation of probability where \textit{Probability} is a reasonable expectation given our beliefs about the system so we can model features beyond the data. We encode our beliefs using the components of \textit{Bayes' Theorem}.

\subsection{Theorems}

\theorem{Samples from a Normal Distribution are $\chi^2$ Distributed}
Let $\X\iid\text{Normal}(\mu,\sigma^2)$. Then
\[\begin{array}{rcl}
{\displaystyle\sum_{i=1}^n\frac{(X_i-\mu)^2}{\sigma^2}}&\sim&\chi^2_n\\
{\displaystyle\sum_{i=1}^n\frac{(X_i-\bar{X})^2}{\sigma^2}}&\sim&\chi^2_{n-1}\\
\end{array}\]

\theorem{Distance between Sample Mean \& Population Mean is $t_r$ Distributed}
Let $\X\iid\text{Normal}(\mu,\sigma^2)$. Then
$$\frac{\sqrt{n}}{s}(\bar{X}-\mu)\sim t_{n-1}$$
\nb We don't need to know $\sigma^2$ to estimate the distance between $\bar{X}$ and $\mu$.\\

\theorem{Multidimension Transform of a Random Variable}
Consider an $n$-dimensional \textit{continuous} random variable $\X\sim f_\X(\cdot)$ which we wish to transform.\\
Define a continuously differentiable bijective function $\textbf{g}:\reals^n\to\reals^n$ and $\textbf{h}:=\textbf{g}^{-1}$.\\
Then if $\textbf{Y}:=\textbf{g}(\textbf{X})\sim f_\text{Y}(\cdot)$ we have
$$f_\textbf{Y}(\textbf{y})=f_\X(\textbf{h}(\textbf{y}))J_\textbf{h}(\textbf{y})$$
where $J_h(\textbf{y}):=\left|\text{det}\left(\dfrac{\partial \textbf{h}}{\partial\textbf{y}}\right)\right|=\left|\text{det}\begin{pmatrix}\frac{\partial h_1}{\partial y_1}&\dots&\frac{\partial h_1}{\partial y_n}\\\vdots&\ddots&\vdots\\\frac{\partial h_n}{\partial y_1}&\dots&\frac{\partial h_n}{\partial y_n}\end{pmatrix}\right|$.

\theorem{Weak Law of Large Numbers}
Let $\{X_n\}_{n\in\nats}$ be a sequence of idependent \& identically distributed random varibles.\\
If $\expect(X_i)=\mu<\infty$ then
$$\frac{1}{n}\sum_{i=1}^nX_i\to_\prob\mu$$

\theorem{Central Limit Theorem}
Let $\{X_n\}_{n\in\nats}$ be a sequence of independent \& indetically distributed with $\expect(X_i)=\mu<\infty$ and $\var(X_i)=\sigma^2<\infty$. Then\\
$$\sqrt\frac{n}{\sigma^2}(Z_n-\mu)\to_\mathcal{D}Z\sim\text{Normal}(0,1)$$

\section{Estimation}

\subsection{Likelihood}

\definition{Likelihood Function}
The \textit{Likelihood Function} is a family of functions which measure the likely of a certain realisation of a random variable is given the parameters of a model have a certain value.
$$L(\pmb{\theta};\x):=Cf_X(\x;\theta)\text{ for }C>0$$
where $\X\sim f_n(\cdot;\pmb{\theta}^*)$ with $\pmb{\theta}^*$ unknown and $\x$ is a realisation of $\X$.\\
\nb \textit{Likelihood Functions} have signature $L(\cdot\x):\theta\to[0,\infty)$.\\
\nb This is also known as the \textit{Observed Likelihood Function}.\\

\definition{Log-Likelihood Function}
The \textit{Log-Likelihhod Function} is the family of functions which are equivalent to the natural log of the \textit{Likelihood Function}.
$$\ell(\theta;\x):=\ln f_n(\x;\theta)+C\text{ for }\underbrace{C}_{\equiv\ln C}\in\reals$$
\nb This is increasing with $L(cdot;\x)$.\\

\remark{Likelihood for Independent \& Identically Distributed Random Variables}
Let $\X\iid f(\cdot;\theta)$ and $\x$ be a realisation of $\X$. Then
\[\begin{array}{rcl}
L_n(\theta;\x)&:=&{\displaystyle\prod_{i=1}^nL(\theta;x_i)}\\
\ell_n(\theta;\x)&:=&{\displaystyle\sum_{i=1}^n\ell(\theta;x_i)}
\end{array}\]

\theorem{The Likelihood Function is Invariant under Bijective Transformations which are independent of Model Parameters}
Consider $\X\sim f_\X(\cdot;\theta)$ and $\textbf{g}:\reals^n\to\reals^n$ be a bijective function which is independent of $\theta$.\\
Define $\textbf{Y}:=\textbf{g}(\X)\sim f_\textbf{Y}(\cdot;\theta)$. Then
$$f_\textbf{Y}(\textbf{y};\theta)\propto f_\X(\textbf{g}^{-1}(\textbf{y});\theta)$$
Hence
$$L_\textbf{Y}(\theta;\textbf{g}(\x))\propto L_\X(\theta;\x)$$

\proof{Theorem 2.1}
Consider $\X\sim f_\X(\cdot;\theta)$ and $\textbf{g}:\reals^n\to\reals^n$ be a bijective function which is independent of $\theta$.\\
Define $\textbf{h}:=\textbf{g}^{-1}$ and $\textbf{Y}:=\textbf{g}(\X)$.\\
We consider the cases where $\X$ is discrete \& continuous independently
\begin{itemize}
	\item[\textit{Discrete Case}] Let $\X$ be a discrete random variable. Then
	\[\begin{array}{rcl}
	f_\textbf{Y}(\textbf{y};\theta)&=&\prob(\textbf{Y}=\textbf{y};\theta)\\
	&=&\prob(\textbf{g}^{-1}(\textbf{Y})=\textbf{g}^{-1}(\textbf{y});\theta)\\
	&=&\prob(h(\textbf{Y})=h(\textbf{Y});\theta)\\
	&=&\prob*\X=h(\textbf{y});\theta)\\
	&=&f_\X(\textbf{g}^{-1}(\textbf{y});\theta)
	\end{array}\]
	\item[\textit{Continuous Case}] Let $\X$ be a continuous random variable.\\
	By \textbf{Theorem 1.3}
	$$f_\textbf{Y}(\textbf{y};\theta)=f_\X(\textbf{g}^{-1}(\textbf{y});\theta)J_{g^{-1}}(\textbf{y})$$
	Since $J_{\textbf{g}^{-1}}$ is independent of $\theta$ this case is solved.
\end{itemize}
In both cases $L_\textbf{Y}(\theta;\textbf{y})=f_\textbf{Y}(\textbf{y};\theta)\propto f_\X(\textbf{g}^{-1}(\textbf{y});\theta)=L_\X(\theta;\x)$.\proved

\definition{Maximum Likelihood Estimate}
Let $\X\sim f_n(\cdot;\theta)$ and $\x$ be a realisation of $\X$.\\
The \textit{Maximum Likelihood Estimate} of $\X$ is the value $\hat\theta\in\Theta$ which produces the greatest value of the \textit{Likelihood Function} of $\X$.
$$\hat\theta_\text{MLE}(\x):=\text{argmax}_\theta L(\theta;\x)=\text{argmax}_\theta\ell(\theta;\x)$$
\nb The \textit{Maximum Likelihood Estimate} is not necessarily unique.\\

\theorem{Maximum Likelihood Estimate of Reparameterisation}
Define random variable $\tau=g(X)$ where $g:\reals\to\reals$. Then
$$\hat\tau_\text{MLE}=\tau(\hat\theta_\text{MLE})$$

\proof{Theorem 2.2}
\textit{This is a proof by contradiction}.\\
Suppose $\exists\ \tau^*\in G$ st $\tilde{f}(x;\tau^*)>\tilde{f}(x;\tau^*)$.\\
We know that $\forall\ \theta\in\Theta,\ f(x;\theta)=\tilde{f}(x;g(\theta))$ and $\forall\ \tau\in G,\ f(x;g^{-1}(\tau))=\tilde{f}(x;\tau)$.\\
We deduce that
\[\begin{array}{rcl}
f(x;g^{-1}(\tau^*))&=&\tilde{f}(x;\tau^*)\\
&>&\tilde{f}(x;\hat{\tau})\text{ by assumption}\\
&=&f(x;g^{-1}(\hat{\tau}))\\
&=&f(x;\hat{\theta})
\end{array}\]
This contradicts the assumption that $\hat{\theta}$ is an maximum likelihood estimate of $\theta$.\proved

\remark{Finding Maximum Likelihood Estimates - Multivariate}
Let $X\sim f_X(\cdot;\pmb\theta)$ be continuous random variable where $f_X(\cdot)$ is differentiable and $\pmb\theta$ is an $n$-dimensional parameter.\\
Let $\x$ be a realisation of $\X$.\\
To find a \textit{Maximum Likelihood Estimate} for $\pmb\theta$
\begin{enumerate}
	\item Find the gradient of $\ell(\pmb\theta;\x)$ wrt $\pmb\theta$.
	$$\nabla\ell(\pmb\theta;\x):=\begin{pmatrix}\frac{\partial}{\partial\theta_1}\ell(\pmb\theta;\x)&\dots&\frac{\partial}{\partial\theta_n}\ell(\pmb\theta;\x)\end{pmatrix}$$
	\item Equate $\nabla\ell(\pmb\theta;\x)$ to the zero-vector and solve for each $\pmb\theta$ to find extrama of $\ell$.
	$$\nabla\ell(\pmb\theta;\x)=\pmb0$$
	\item Calculate the \textit{Hessian} of $\ell(\pmb\theta;\x)$
	$$\nabla^2\ell(\pmb\theta;\x)=\begin{pmatrix}\frac{\partial}{\partial\theta_1^2}\ell(\pmb\theta;\x)&\dots&\frac{\partial}{\partial\theta_1\theta_n}\ell(\pmb\theta;\x)\\\vdots&\ddots&\vdots\\\frac{\partial}{\partial\theta_n\theta_1}\ell(\pmb\theta;\x)&\dots&\frac{\partial}{\partial\theta_n^2}\ell(\pmb\theta;\x)\end{pmatrix}$$
	\item Test each extremum $\pmb{\hat\theta}$ to see if it is a maximum
\begin{center}If $\text{det}(H(\pmb{\hat\theta}))>0$ and $\frac{\partial}{\partial\theta_1^2}\ell(\pmb{\hat\theta};\x)<0$ then $\pmb{\hat\theta}$ is a local maximum.\end{center}
\ie Check $H(\pmb{\hat\theta})$ is \textit{negative definite}.\\
\end{enumerate}

\definition{Likelihood Ratio}
Let $\X\iid f(\cdot;\theta^*)$ for $\theta^*\in\Theta$ and $\{\hat\theta_i\}_{n\in\nats}$ be a sequence of consistent \textit{Maximum Likelihood Estimaors} of $\theta^*\in\Theta$.\\
We define the \textit{Likelihood Ratio} as
$$\Lambda_n(\x):=\frac{L(\theta^*;\x)}{L(\hat\theta_n;\x}\in[0,1]\text{ for }\x\in\mathcal{X}^n$$

\theorem{Asymptotic Distribution of Likelihood Ratio}
Let $\X\iid f(\cdot;\theta^*)$ for $\theta^*\in\Theta$ and $\{\hat\theta_i\}_{n\in\nats}$ be a sequence of consistent \textit{Maximum Likelihood Estimaors} of $\theta^*\in\Theta$.\\
Suppose the conditions of \textbf{Theorem 2.13} hold (\ie $X_n$ is asymptotically normal). Then
$$-2\ln\Lambda_n(\X_n)\to_{\mathcal{D}(\cdot;\theta^*)}\chi^2_1$$

\subsection{Estimators}

\definition{Estimation}
Let $\X\sim f_n(\cdot;\theta^*)$ with $\theta^*\in\Theta$ and $\x$ be a realisation of $\X$.\\
As \textit{Estimation} of model parameter $\theta^*$ is a statistic, $\hat\theta(\x)=T(\x)$, which is indtended to approximated the true value of $\theta^*$.\\
\nb Interchangeable with \textit{Estimate}.\\

\definition{Estimator}
Let $\X\sim f_n(\cdot;\theta^*)$ with $\theta^*\in\Theta$ and $\x$ be a realisation of $\X$.\\
An \textit{Estimator} of model paramter $\theta^*$ is the random variable $\hat\theta:=\hat\theta(\X)$ where $\hat\theta(\x)$ is an \textit{estimation} of $\theta^*$.\\

\definition{Bias}
The \textit{Bias} of an \textit{Estimator}, $\hat\theta$, is its expected error.\\
\ie By how much an estimator consistently deviates from the true value of the parameter).\\
Let $\theta^*$ be the true value of parameter $\theta$. Then
\[\begin{array}{rrl}
\text{Bias}(\hat\theta;\theta^*)&:=&\expect(\hat\theta-\theta^*;\theta^*)\\
&=&\expect(\hat\theta;\theta^*)-\theta^*
\end{array}\]
\nb An \textit{Estimator} is \textit{Unbiased} if $\forall\ \theta\in\Theta\ \text{Bias}(\theta^*;\theta)=0\Longleftrightarrow\expect(\hat\theta;\theta)=\theta$.\\

\definition{Mean Square Error}
The \textit{Mean Square Error} of an \textit{Estimator}, $\hat\theta$, measures the average of its square error.\\
Let $\theta^*$ be the true value of parameter $\theta$. Then
\[\begin{array}{rrl}
\text{MSE}(\hat\theta;\theta^*)&:=&\expect\left[(\hat\theta(\X)-\theta^*)^2;\theta^*\right]\\
&=&\var(\hat\theta;\theta^*)+\text{Bias}(\hat\theta;\theta^*)^2
\end{array}\]

\definition{Distribution of an Estimator}
Let $\X\sim f_n(\cdot;\theta^*)$ with $\theta^*\in\Theta\subseteq\reals$.\\
Let $\hat\theta(\X)$ be a real-valued \textit{Estimator} of $\theta^*$. Then
\[\begin{array}{rrl}
F_{\hat\theta(\X)}(t;\theta^*)&:=&\prob(\hat\theta(\X)\leq t;\theta^*)\\
&=&{\displaystyle\int_{\mathcal{X}^n}}\mathds{1}\{\hat\theta(\x)\leq t\}f_n(\x;\theta^*)d\x
\end{array}\]
\nb The distribution of an \textit{Estimator} depends on the true value of the parameter it is estimating.\\
\nb As sample size increases the distribution of an estimator should converge to a more standard distribution.

\subsection{Confidence Sets}

\definition{Random Interval}
A \textit{Random Interval} is an interval of values which depends on a random variable and thus does not have fixed values.
$$\mathcal{I}(\X):=[L(\X),U(\X)]$$

\definition{Observed Confidence Interval}
Let $\X$ be a random variable, $\mathcal{I}(\X):=[L(\X),U(\X)]$ and $\x$ be a realisation of $\X$.\\
$\mathcal{I}(\x)=[L(\x),U(\x)]$ is an \textit{Observed Confidence Interval}.\\

\definition{Coverage of an Interval}
Let $\X\sim f_n(\cdot;\theta)$ for $\theta\in\Theta=\reals$.\\
Define $L:\mathcal{X}^n\to\Theta\ \&\ U:\mathcal{X}^n\to\Theta$ st $\forall\ \x\in\mathcal{X}^n,\ L(\x)<U(\x)$.\\
The \textit{Coverage} of the \textit{Random Interval} $\mathcal{I}(\X):=[L(\X),U(\X)]$ at $\theta$ is defined to be
$$C_\mathcal{I}(\theta):=\prob(\theta\in[L(\X),U(\X)];\theta)$$
\nb \textit{Coverage} is the probability that a realisation of a random variable lies in a given random interval for a given parameter value.\\

\definition{Confidence Interval}
Let $\alpha\in[0,1]$ and $\mathcal{I}(\X):=[L(\X),U(\X)]$ be a random interval.\\
We say that $\mathcal{I}(\X)$ is a $1-\alpha$ \textit{Confidence Interval} if
$$\forall\ \theta\in\Theta,\ C_\mathcal{I}(\theta)\geq1-\alpha$$
\nb $\mathcal{I}(\X)$ is an \textit{\underline{Exact} Confidence Interval} if $\forall\ \theta\in\Theta,\ C_\mathcal{I}(\theta)=1-\alpha$.\\

\proposition{Transformed Confidence Interval}
Let $\X\sim f(\cdot;\theta^*)$ for $\theta^*\in\Theta$ and $\mathcal{I}(\X):=[L(\X),U(\X)]$ be a confidence interval for $\theta^*$.\\
Let $\tau:=g(\theta)$ be a bijective, continuously diferential function. If
\begin{itemize}
	\item[-] $g(\cdot)$ is \textbf{increasing} then $[L(\x),U(\x)]=[g(L(\x)),g(U(\x))]$.
	\item[-] $g(\cdot)$ is \textbf{decreasing} then $[L(\x),U(\x)]=[g(U(\x)),g(L(\x))]$.
\end{itemize}

\proposition{Confidence Interval for Reparameterisations}
Let $\X_n\sim f(\cdot;\theta^*)$ for $\theta^*\in\Theta\subseteq\reals$ and $\tau_n:=g(\theta)$ be a bijective \& continuously differentiable function.\\
When $\X_n$ is a regular statistical model we have
$$\sqrt{n\tilde{I}(\tau^*)}(\hat\tau_n-\tau^*)\to_{\mathcal{D}(\cdot;\tau^*)}Z\sim\text{Normal}(0,1)$$
which leads to the \textit{Confidence Interval}
$$\tilde{\mathcal{I}}(\X):=[\tilde{L}(\X),\tilde{U}(\X)]\text{ where }\tilde{L}(\X)=\hat\tau_n-z_{\alpha/2}\sqrt{\dfrac{g'(\theta^*)^2}{nI(\theta^*)}}\text{ and }\tilde{U}(\X)=\hat\tau_n+z_{\alpha/2}\sqrt{\dfrac{g'(\theta^*)^2}{nI(\theta^*)}}$$
\nb This confidence interval is \textbf{not} necessarily the same as transforming $[L(\x),U(\x)]$ directly.\\

\proposition{Confidence Intervals with unknown variance, $\sigma^2$}
When variance, $\sigma^2$, is unknown we can define a consistent sequence of estimators $\{\hat\sigma^2_n\}_{n\in\nats}$ 
$$\hat\sigma_n^2:=\frac{1}{n-1}\sum_{i=1}^n(\X_i-\hat\mu_n)^2$$

\definition{Wald's Approach}
Let $\X\iid f(\cdot;\theta^*)$ for $\theta^*\in\Theta\subset\reals$.\\
Using \textit{Wald's Approach} we can define a confidence interval for $\theta^*$ using the asymptotic distribution of the \textit{Maximum Likelihood Estimator} for $\theta^*$.
$$\mathcal{I}(\tau^*):=[L(\X),U(\X)]\text{ where } L(\x):=\hat\theta_n-z_{\alpha/2}\sqrt{nI(\theta^*)}\text{ and }U(\x)=\hat\theta_n+z_{\alpha/2}\sqrt{nI(\theta^*)}$$
\nb This definition ensures that as $\prob(\theta\in\mathcal{I}(\X))\underset{n\to\infty}{\longrightarrow}1-\alpha$.\\

\remark{Limitations of Wald's Approach}
Let $\mathcal{I}(\theta^*)$ be a \textit{Confidence Interval} defined using \textit{Wald's Approach}.\\
There are certain limitations of \textit{Wald's Approach}
\begin{enumerate}
	\item It is possible $\exists\ \theta\not\in\mathcal{I}(\theta^*)$ st $\exists\ \theta'\in\mathcal{I}(\theta^*)$ where $L(\theta;\x)>L(\theta';\x)$.
	\item It is possible $\exists\ \theta\in\mathcal{I}(\theta^*)$ where $L(\theta;\x)=0$.
	\item \textit{Wald Confidence Interval}s are not invariant under reparameterisation.
\end{enumerate}

\definition{Confidence Set}
Let $\X_n\iid f_n(\cdot;\theta^*)$ for $\theta^*\in\Theta$ and $\hat\theta_n$ be an estimator of $\theta$.\\
\textit{Confidence Sets} for $\theta^*$ are the possible values of $\theta$ whoses likelihood is close to that of the \textit{Maximum Likelihood Estimate} of $\theta$.\\
\textit{Confidence Sets} are not necessarily contiguous.
$$C(\X_n):=\left\{\theta\in\Theta:\ell(\hat\theta_n;\X_n)-\ell(\theta;\X_n)\leq\frac{1}{2}\chi^2_{1,\alpha}\right\}\subseteq\Theta$$
\textit{Confidence Interval} sets are asymptotically $1-\alpha$ for $\theta^*$ since
$$\prob(\theta^*\in C(\X_n);\theta^*)\underset{n\to\infty}{\longrightarrow}1-\alpha$$
\nb This definition and result are applications of \textbf{Definition 2.4} \& \textbf{Theorem 2.3}.\\
\nb \textit{Confidence Sets} are hard to define explicitly without a computer.\\
\nb This is known as \textit{Wilk's Approach}.\\

\theorem{Confidence Set of Reparameterisation}
Let $\X\sim f(\cdot;\theta^*)$ for $\theta^*\in\Theta$ and $\tau:=g(\theta)$  where $g:\Theta\to G$ is a \underline{bijection}.\\
Let $C(\x)$ be a confidence set for $\theta^*$ and $\tilde{C}(\x)$ be a confidence set for $\tau^*$. Then
$$\forall\ \x\in\mathcal{X}^n,\ \theta^*\in\Theta\text{ we have }\theta\in C(\x)\Longleftrightarrow g(\theta\in\tilde{C}(\x))$$
\nb $\tilde{C}(\x):=\left\{\theta\in\Theta:\tilde\ell_n(\hat\theta_n;\x)-\tilde\ell(\theta;\x)\leq\frac{1}{2}\chi^2_{1,\alpha}\right\}$.\\

\proof{Theorem 2.4}
Let $\x\in\chi^n$ be arbitrary.\\
Everything rests on the observation that
$$\forall\ \theta\in\Theta,\ \ell(\theta;\x)=\ln f(\x;\theta)=\ln f(\x;g(\theta)=\tilde\ell(g(\theta;\x)$$
and similary
$$\forall\ \tau\in G,\ \tilde\ell(\tau;\x)=\ln \tilde{f}(\x;\tau)=\ln f(\x;g^{-1}(\tau))=\ell(g^{-1}(\tau);\x)$$
Note that $g(\hat\theta_n)$ is the \textit{Maximum Likelihood Estimate} of $\tau$.\\
Assume $\theta\in C(\x)$. Then
$$-2\left[\ell(\theta;\x)-\ell(\hat\theta_n;\x)\right]\leq\chi^2_{1,\alpha}$$
Thus
$$-2\left[\tilde\ell(g(\theta);\x)-\tilde\ell(g(\hat\theta_n);\x)\right]\leq\chi^2_{1,\alpha}$$
Thus $g(\theta\in\tilde{C}(\x)$.\\
So $\theta\in C(\x)\implies g(\theta)\in\tilde{C}(\x)$.\\
\\
Similarly, assume that $g(\theta)\in\tilde{C}(\x)$. Thus
$$-2\left[\ell(\theta;\x)-\ell(\hat\theta_n;\x)\right]\leq\chi^2_{1,\alpha}$$
Thus $\theta\in C(\x)$.\\
So $\theta\in C(\x)\Longleftrightarrow g(\theta)\in\tilde{X}(\x)$.\\
\\
For the last part, this correspondence implies that
$$\{\x\in\chi^n;\theta^*\in C(\x)\}=\{\x\in\chi^2:g(\theta^*)\in\tilde{C}(\x\}$$
Thus, we can conclude from the equivalnce of the events
$$\{\theta^*\in C(\X)=\{g(\theta^*)\in\tilde{C}(\X)\}$$

\remark{Confidence Set Rule of Thumb}
Under the conditions of \textbf{Theorem 2.3} there is a rule of thumb that
$$\prob(\theta^*\in C(\x))\approx0.95\text{ where }C\approx\left\{\theta\in\Theta:\ell(\hat\theta_n;\x)-\ell(\theta;\x)\leq2\right\}$$

\subsection{Convergence}

\definition{Convergence}
Let $\{z_n\}_{n\in\nats}$ be a deterministic sequence of real values and $z\in\reals$.\\
We say $\{z_n\}$ \textit{converges} to limit $z$ if
$$\forall\ \varepsilon>0\ \exists\ n_0\in\nats\text{ st }\forall\ n\geq n_0\quad |z_n-z|\leq\varepsilon$$
\nb This is the same for vectors.\\

\definition{Convergence in Probability}
Let $\{Z_n\}_{n\in\nats}$ be a sequence of random variables and $Z$ be a random variable in the same probability space.\\
We say that $\{Z_n\}_{n\in\nats}$ \textit{Converges in Probability} to $Z$ if
$$\forall\ \varepsilon>0\quad\lim_{n\to\infty}\prob(|Z_n-Z|>\varepsilon)=0$$
\nb This is denoted as $Z_n\to_\prob Z$.\\

\definition{Convergence in Distribution}
Let $\{Z_n\}_{n\in\nats}$ be a sequence of random variables and $Z$ be a random variable, not necessarily in the same probability space.\\
We say $\{Z_n\}_{n\in\nats}$ \textit{Converges in Distribution} to $Z$ if
$$\forall\ z\in Z\text{ where }F_Z(z)\text{ is continuous }\lim_{n\to\infty}F_{Z_n}(z)=F_Z(z)$$
\ie $F_{X_n}$ converges in value to $F_X$ as $n\to\infty$.\\
\nb This is dentoed as $Z_n\to_\mathcal{D}Z$.\\

\definition{Convergence in Quadratic Mean}
Let $\{Z_n\}_{n\in\nats}$ be a sequence of random variables and $Z$ be a random variable, not necessarily in the same probability space.\\
We say $\{Z_n\}_{n\in\nats}$ \textit{Converges in Quadratic Mean} to $Z$ if
$$\lim_{n\to\infty}\expect\left[(Z_n-Z)^2\right]=0$$
\nb This is denoted as $Z_n\to_\text{qm}Z$.\\

\theorem{$Z_n\to_\prob Z\implies Z_n\to_\mathcal{D}Z$}

\theorem{$Z_n\to_\text{qm}Z\implies Z_n\to_\prob Z$}

\theorem{$Z_n\to_\prob a\Longleftrightarrow Z_n\to_\mathcal{D} a\text{ for }a\in\reals$}

\theorem{Continuous Mapping Theorem}
Let $\{Z_n\}_{n\in\nats}$ be a sequence of random variabesl and $Z$ be a random varible.\\
Let $g:Z\to G$ be a function which maps from the space of random variable $Z$ to a space $G$. Then
\begin{enumerate}
	\item If $Z_n\to_\prob Z$ then $g(Z_n)\to_\prob g(Z)$.
	\item If $Z_n\to_\mathcal{D}Z$ then $g(Z_n)\to_\mathcal{D}g(Z)$.
\end{enumerate}

\theorem{Slutsky's Theorem}
Let $\{Y_n\}_{n\in\nats}\ \&\ \{Z_n\}_{n\in\nats}$ be sequences of random varibles, $Y$ be a random variables \& $c\in\reals\backslash\{0\}$.\\
If $Y_n\to_\mathcal{D} Y$ and $Z_n\to_\mathcal{D} c$. Then
\begin{enumerate}
	\item $Y_n+Z_n\to_\mathcal{D}Y+c$.
	\item $Y_nZ_n\to_\mathcal{D}Yc$.
	\item $\dfrac{Y_n}{Z_n}\to_\mathcal{D}\dfrac{Y}{c}$.
\end{enumerate}

\definition{Consistent Sequence of Estimators}
Let $\X_n\sim f_n(\cdot;\theta)$ be a random vector and $\{\hat\theta_n(\cdot):\mathcal{X}^n\to\Theta\}_{n\in\nats}$ be a sequence of estimators for $\theta$.\\
We say $\{\hat\theta_n\}$ is \textit{Consistent} if
$$\forall\ \theta\in\Theta\quad\hat\theta_n(\X_n)\to_{\prob(\cdot;\theta)}\theta$$

\theoremm{$\hat\theta_n\to_\text{qm}\theta\implies\{\hat\theta_n\}$ is consistent}

\subsection{Performance of Estimators}

\remark{Measuring Performance of an Estimator}
We measure the performance of an estimator $\hat\theta$ in terms of variance since its mean should be $\theta^*$ and is thus a bad measure.\\
Lower variance indicates better performance.\\

\definition{Fisher Information Regularity Conditions}
Define $\Theta\subset\reals$ and $f(x;\theta)$ be a probability mass/density function.\\
If a model fulfils the following criteria then it is sufficiently \textit{regular} for \textit{Fisher Information} to be drawn from it
\begin{enumerate}[label=\roman*)]
	\item $\forall\ x\in\mathcal{X}$ \textbf{both} $L'(\theta;x)=\frac{d}{d\theta}f(x;\theta)$ and $L''(\theta;x)=\frac{d^2}{d\theta^2}f(x;\theta)$ \textit{exist}.
	\item $\forall\ \theta\in\Theta$ the set $S:=\{x\in\mathcal{X}:\ f(x;\theta)>0\}$ is \textit{independent} of $\theta\in\Theta$.
	\item The idenity below \textit{exists}
	$$\int_S\frac{d}{d\theta}f(x;\theta)dx=\frac{d}{d\theta}\int_Sf(x;\theta)dx=0$$
\end{enumerate}
\nb Statistical Models which fulfil all these criteria are described as \textit{Regular}.\\

\definition{Score Function - Single Random Variable}
Let $X\sim f(\cdot;\theta)$ for some $\theta\in\Theta$ and $x$ be a realisation of $X$.\\
The \textit{Score Function} measures the sensitivity of the likelihood function  wrt the parameter it is estimating.
$$\ell'(\theta;x):=\frac{d}{d\theta}\ell(\theta;x)=\frac{\frac{d}{d\theta}f(x;\theta)}{f(x;\theta)}$$

\definition{Score Function - Independent \& Identically Distributed Random Variables}
Let $\X\iid f(\cdot;\theta)$ with $\theta\in\Theta$ and $\x$ be a realisation of $\X$.
$$\ell'_n(\theta;\x):=\sum_{i=1}^n\frac{d}{d\theta}\ell(\theta;x_i)$$

\prooff{By Regularity Conditions $\expect(\ell'(\theta;X);\theta)=0\ \forall\ \theta\in\Theta$}
\[\begin{array}{rcl}
\expect(\ell'(\theta;X);\theta)&=&{\displaystyle\int_S\dfrac{\frac{d}{d\theta}f(x;\theta)}{f(x;\theta)}f(x;\theta)dx}\\
&=&{\displaystyle\int_S\frac{d}{d\theta}f(x;\theta)dx}\\
&=&{\displaystyle\frac{d}{d\theta}\int_Sf(x;\theta)dx}\\
&=&\frac{d}{d\theta}(1)\\
&=&0\ \forall\ \theta\in\Theta
\end{array}\]

\definition{Fisher Information - Single Random Variable}
Let $X\sim f(\cdot;\theta)$ be an sufficiently regular (see \textbf{Definition 2.14}) observable random variable with $\theta$ unknown.\\
\textit{Fisher Information} measures the amount of information $X$ carries about $\theta$.
\[\begin{array}{rrl}
I(\theta)&:=&\expect(\ell'(\theta;X)^2;\theta)\\
&=&\var(\ell'(\theta;X);\theta)\text{ by \textbf{Proof 2.3}}
\end{array}\]
\nb This is the expectation of the score, squared $\equiv$ The second moment of the score.\\

\definition{Fisher Information - Independent \& Identically Distributed Random Variables}
Let $\X\iid f(\cdot;\theta)$ with $\theta\in\Theta$ and $\x$ be a realisation of $\X$.
\[\begin{array}{rrl}
I_n(\theta)&:=&\expect(\ell'_n(\theta;\X)^2;\theta)\\
&=&\var(\ell'_n(\theta;\X);\theta)\\
&=&nI(\theta)
\end{array}\]

\definition{Observed Fisher Information}
Let $\X\iid f(\cdot;\theta^*)$ be a random n-dimensional vector.\\
The \textit{Observed Fisher Information} at $\theta$ is
$$nJ_n(\theta)=-\ell''(\theta;\X)=-\sum_{i=1}^n\ell''(\theta;X_i)$$
\nb $\expect(J_n(\theta^*;\theta^*)=I(\theta^*)$. This is a deterministic value, not an expectation like \textit{Fisher Information}.\\

\theorem{Fisher Information of Reparameterisation}
Let $X\sim f(\cdot;\theta)$ for $\theta\in\Theta\subseteq\reals$ and $\tau:=g(\theta)$ be a bijective \& continuously differentiable function.\\
Consider the reparameterisation $\tilde{f}(x;\tau):=f(x;g(\theta))=f(x;g^{-1}(\tau))$.\\
The \textit{Fisher Information} for this reparameterisation, $\tilde{f}$ is given by
$$\tilde{I}(\tau)=\frac{I(\theta)}{g'(\theta)^2}$$

\proof{Theorem 2.9}
Since $\tilde{f}(x;\tau)=f(x;g^{-1}(\tau))$ the log-likelihood for $tau$ is
$$\tilde\ell(\tau;x)=\ln\tilde{f}(x;\tau)=\ln f(x;g^{-1}(\tau))$$
The score is therefore
\[\begin{array}{rcl}
\tilde\ell'(\tau;x)&=&\frac{d}{d\tau}\ln f(x;g^{-1}(\tau))\\
&=&\frac{d}{d\theta}\ln f(x;g^{-1}(\tau))\times\frac{d}{d\tau}g^{-1}(\tau)\\
&=&\ell'(g^{-1}(\tau);x)\times\dfrac{1}{g'(g^{-1}(\tau))}\\
&=&\dfrac{\ell'(\theta;x)}{g'(\theta)}
\end{array}\]
No we use the definition of \textit{Fisher Information}
\[\begin{array}{rcl}
\tilde{I}(\tau)&=&\expect(\tilde\ell'(\tau;X)^2;\tau)\\
&=&\expect\left(\dfrac{\ell'(\theta;X)^2}{g'(\theta)^2};\theta\right)\\
&=&\dfrac{1}{g'(\theta)^2}\expect\left(\ell'(\theta;X)^2;\theta\right)\\
&=&\dfrac{I(\theta)}{g'(\theta)^2}
\end{array}\]

\theorem{Alternative Expression of Fisher Information}
Let $X\sim f(\cdot;\theta)$ be a sufficiently regular random variable. Then
$$\text{if }\forall\ \theta\in\Theta\ \int_\mathcal{X}\frac{d^2}{d\theta^2}f(x;\theta)dx=\frac{d}{d\theta}\int_\mathcal{X}\frac{d}{d\theta}f(x;\theta)dx\text{ then }I(\theta)=-\expect\left(\frac{d^2}{d\theta^2}\ell(\theta;X);\theta\right)$$

\proof{Theorem 2.9}
By the \textit{Quotient Rule}
\[\begin{array}{rcl}
\frac{d^2}{d\theta^2}\ell(\theta;x)&=&\dfrac{d}{d\theta}\dfrac{\frac{d}{d\theta}f(x;\theta)}{f(x;\theta)}\\
&=&\dfrac{\frac{d^2}{d\theta^2}f(x;\theta)}{f(x;\theta)}-\left(\dfrac{\frac{d}{d\theta}f(x;\theta)}{f(x;\theta)}\right)^2
\end{array}\]
Consequently
\[\begin{array}{rrcl}
&\expect\left(\frac{d^2}{d\theta^2}\ell(\theta;X);\theta\right)&=&{\displaystyle\int_S\frac{\frac{d^2}{d\theta^2}f(x;\theta)}{f(x;\theta}f(x;\theta)dx-\int_S\left(\frac{\frac{d}{d\theta}f(x;\theta)}{f(x;\theta)}\right)^2f(x;\theta)dx}\\
&&=&{\displaystyle\int_S\frac{d^2}{d\theta^2}f(x;\theta)dx-\int_S\ell'(\theta;x)^2f(x;\theta)dx}\\
&&=&0-\expect(\ell'(\theta;X)^2;\theta)\\
&&=&-I(\theta)\\
\implies&I(\theta)&=&-\expect\left(\frac{d^2}{d\theta^2}\ell(\theta;X);\theta\right)
\end{array}\]
\proved

\theorem{Distribution of Maximum Likelihood Estimators for Regular Models}
Let $\X_n\iid f_n(\cdot;\theta^*)$ be a sufficiently regular statistically model and $\{\hat\theta_n\}_{n\in\nats}$ be a consistent sequence of \textit{Maximum Likelihood Estimators} for $\theta^*$. Then
$$\sqrt{nI(\theta^*)}(\hat\theta_n-\theta^*)\to_{\mathcal{D}(\cdot;\theta^*)}Z\sim\text{Normal}(0,1)$$
Here $I(\theta^*)$ is unknown so we replace it with
\begin{enumerate}
	\item $I(\hat{\theta}_n)$ when
	\begin{enumerate}
		\item $I(\theta)$ is continuous in a neighbourhood of $\theta^*$;
		\item And, the interval $[L(\X),U(\X)]$ with $L(\x):=\hat{\theta}_n-z_{\alpha/2}\sqrt{nI(\hat{\theta}_n)}$ and ${U(\x):=\hat{\theta}_n+z_{\alpha/2}\sqrt{nI(\hat{\theta}_n)}}$ is an asymptotically exact $1-\alpha$ confidence interval for $\theta*$.
	\end{enumerate}
	\item $J_n(\hat{\theta}_n):=-\frac{1}{n}\sum\limits_{i=1}^n\ell''(\hat{\theta}_n;X_i)$ when
	\begin{enumerate}
		\item $\hat\theta_n\to_{\prob(\cdot;\theta^*)}\theta^*$;
		\item $I(\theta)=-\expect(\ell''(\theta;X);\theta)\ \forall\ \ theta\in\Theta$;
		\item $\exists\ C:\mathcal{X}\to[0,\infty)$ st $\expect(C(X_1);\theta^*)<\infty,\ \Xi\subset\Theta$ is an open set containing $\theta^*$ and $\Delta(\cdot):\Xi\to[0,\infty)$ is continuous at 0 st $\Delta(0)=0$, and st $\forall\ \theta,\theta^*,x\in \Xi^2\times\mathcal{X}$
		$$|\ell''(\theta;x)-\ell''(\theta';x)|\leq C(x)\Delta(\theta-\theta')$$
		\item And, the interval $[L(\X),U(\X)]$ with $L(\x):=\hat{\theta}_n-z_{\alpha/2}\sqrt{nJ_n(\hat{\theta}_n)}$ and ${U(\x):=\hat{\theta}_n+z_{\alpha/2}\sqrt{nJ_n(\hat{\theta}_n)}}$ is an asymptotically exact $1-\alpha$ confidence interval for $\theta^*$
	\end{enumerate}
\end{enumerate}

\theorem{Cramer-Rao Inequality}
Let \textit{Cramer-Rao Inequality} provides us with a \textit{lower bound} for the performance of all estimators.\\
Let $\X_n\iid f(\cdot;\theta)$ be a sufficiently regular random vector and $\hat\theta_n(\cdot)$ be an estimator of $\theta$ with expectation $m_1(\theta):=\expect(\hat\theta_n(\X_n);\theta)$.\\
$$\text{if }\forall\ \theta\in\Theta,\ \underbrace{\frac{d}{d\theta}\int\hat{\theta}_n(\x)f_n(\x;\theta)d\x}_{\expect(\hat{\theta}_n)}=\int\hat{\theta}_n(\x)\frac{d}{d\theta}f_n(\x;\theta)d\x$$
Then
$$\forall\ \theta\in\Theta,\ \var(\hat\theta_n(\X);\theta)\geq\frac{m_1'(\theta)^2}{nI(\theta)}$$

\proof{Cramer-Rao Inequality}
We notice that
\[\begin{array}{rcl}
m'(\theta)&=&\frac{d}{d\theta}\expect(\hat{\theta}_n(\X_n);\theta)\\
&=&\frac{d}{d\theta}\int_{S^n}\hat{\theta}_n(\x_n)f_n(\x_n;\theta)d\x_n
\end{array}\]
The clever part of this proof is to observe that
\[\begin{array}{rcl}
\var(\hat{\theta}_n(\X_n);\theta)nI(\theta)&=&\var(\hat{\theta}_n(\X_n);\theta)\var(\ell_n(\theta;\X_n);\theta)\\
&\geq&\cov(\hat{\theta}_n(X_n),\ell'_n(\theta;\X_n);\theta)^2\text{ by Covariance Inequality}
\end{array}\]
Thus
\[\begin{array}{rrcl}
&\cov(\hat{\theta}_n(X_n),\ell'_n(\theta;\X_n);\theta)^2&=&\expect(\hat{\theta}_n(X_n)\ell_n'(\theta;\X_n);\theta)-\expect(\hat{\theta}_n(\X_n);\theta)\expect(\ell'_n(\theta;\X_n);\theta)\\
&&=&\expect(\hat{\theta}_n(X_n)\ell_n'(\theta;\X_n);\theta)-\expect(\hat{\theta}_n(\X_n);\theta)\times0\\
&&=&\expect(\hat{\theta}_n(X_n)\ell_n'(\theta;\X_n);\theta)\\
&&=&{\displaystyle\int_{S^n}\hat{\theta}_n(\x_n)\ell'_n(\theta;\x_n)f_n(\x_n;\theta)d\x_n}\\
&&=&{\displaystyle\int_{S^n}\hat{\theta}_n(\x_n)\frac{\frac{d}{d\theta}f_n(\x_n;\theta)}{f_n(\x_n;\theta)}f_n(\x_n;\theta)d\x_n}\\
&&=&{\displaystyle\int_{S^n}}\hat{\theta}_n(\x_n)\frac{d}{d\theta}f_n(\x_n;\theta)\\
&&=&\frac{d}{d\theta}{\displaystyle\int_{S^n}\hat{\theta}_n(\x_n)f_n(\x_n;\theta)d\x_n}\text{ by regularity assumption}\\
&&=&m'(\theta)\\
\implies&\var(\hat{\theta}_n(X_n);\theta)nI(\theta)&\geq&m'(\theta)^2
\end{array}\]

\remark{Cramer-Rao Inequality with an Unbiased Estimator}
Let $\hat\theta_n$ be an unbiased estimator of $\theta$ (\ie $m_1(\theta)=\theta$). Then
$$\var(\hat\theta_n(\X_n);\theta)=\text{MSE}(\hat\theta_n(\X_n);\theta)\geq\frac{1}{nI(\theta)}$$

\subsection{Asymptotic Distribution of Estimators}

\theorem{Asymptotic Distribution of Maximum Likelihood Estimators}
Suppose that $\X_n\iid f(\cdot;\theta^*)$ for some $\theta^*\in\Theta$ and assume that
\begin{enumerate}[label=\roman*)]
	\item The sequence of maximum likelihood estiamtors $\{\hat{\theta}_n(\X_n)\}$ is consistent;
	\item The \textit{Fisher Information Regularity Conditions} (\textbf{Definition 6.2}) hold and ${I(\theta^*)=-\expect[\ell''(\theta;X);\theta]>0}$.
	\item $\exists\ C:\mathcal{X}\to[0,\infty)$ such that $\expect[C(X_1);\theta^*]<\infty$ and $\Delta:\Xi\to[0,\infty)$, where $\Xi\subset\Theta$ st $\theta^*\in\Xi$, that is continuous at 0 st $\Delta(0)=0$, such that 
	$$\forall\ (\theta,\theta',x')\in\chi^2\times\mathcal{X},\quad|\ell''(\theta;x)-\ell(\theta';x)|\leq C(x)\Delta(\theta-\theta')$$
\end{enumerate}
Then $\forall\ \theta^*\in\Theta$
$$\sqrt{nI(\theta^*)}(\hat{\theta}_n(\X_n)-\theta^*)\to_{\mathcal{D}(\dot;\theta^*)}Z\sim\text{Normal}(0,1)$$

\proof{Theorem 2.11}
By \textbf{Theorem 2.11} $\ell'_n(\hat{\theta}_n;\X)=\ell'_n(\theta^*;\X)+(\hat{\theta}_n-\theta^*)[\ell''_n(\theta^*;\X)+R_n]$ where $\frac{1}{n}R_n\to_{\prob(\cdot;\theta^*)}0$.\\
Since $\hat{\theta}_n$ is the maximum likelihood estimator \& the \textit{Fisher Information Regularity Conditions} hold, the score at $\ell'(\hat{\theta}_n;X)=0$.\\
Hence, $0=\ell''(\hat{\theta}_n;X)=\ell'_n(\theta;X)+(\hat{\theta}_n-\theta^*)\{\ell''(\theta;X)+R_n\}$.\\
Rearranging \& rescalling by $\sqrt{n}$ gives
$$\sqrt{n}(\hat{\theta}_n-\theta^*)=\frac{\frac{1}{\sqrt{n}}\ell'(\theta^*;X)}{-\frac{1}{\sqrt{n}}\{\ell''(\theta^*;X)+R_n}=:\frac{U_n}{V_n-\frac{R_n}{n}}$$
Recall that $\ell'_n(\theta^*;X)=\sum\limits_{i=1}^n\ell'(\theta;X_i)$ and $\ell''_n(\theta^*;X)=\sum\limits_{i=1}^n\ell''(\theta^*;X_i)$.\\
Since $\expect(\ell'(\theta^*;X_i);\theta^*)=0$ and $\var(\ell'(\theta^*;X_i);\theta^*)=I(\theta^*)$\\$\implies U_n\to_{\mathcal{D}(\cdot;\theta^*)}U\sim\text{Normal}(0,I(\theta^*))$ by the \textit{Central Limit Theorem}.\\
We observed that $V_n\to_{\prob(\cdot;\theta^*)}I(\theta^*)$ by the \textit{Weak Law of Large Numbers} since ${\expect(-\ell''(\theta^*;X_i);\theta^*)=I(\theta^*)}$.\\
It follows that $V_n-\frac{1}{n}R_n\to_{\prob(\cdot;\theta^*)}I(\theta^*)$ by \textit{Slutsky's Theorem}.\\
Using \textit{Slutsky's Theorem} again
$$\sqrt{n}(\hat{\theta}_n-\theta^*)=\frac{U_n}{V_n-\frac{1}{n}R_n}\to_{\mathcal{D}(\cdot;\theta^*)}\frac{\sqrt{I(\theta^*)}}{I(\theta^*)}Z\text{ where }Z\sim\text{Normal}(0,1)$$
We can rewrite this as
$$\sqrt{nI(\theta^*)}(\hat{\theta}_n-\theta^*)\to_{\mathcal{D}(\cdot;\theta^*)}Z\sim\text{Normal}(0,1)$$

\theorem{Convergence of Score of Maximum Likelihood Estimators}
Under the conditions in \textbf{Theorem 2.11}, with $\hat\theta_n$ a Maximum Likelihood Estimator
$$\ell'_n(\hat\theta_n;\X)=\ell'_n(\theta^*;\X)+(\hat\theta_n-\theta^*)[\ell''_n(\theta^*;\X)+R_n\}$$
where $\frac{1}{n}R_n\to_{\prob(\cdot;\theta^*)}0$.\\

\proof{Theorem 2.12}
\textit{This is an non-examinable, sketch proof of \textbf{Theorem 8.2}}.\\
By the regularity conditions and the mean alue theorem
$$\frac{\ell_n'(\theta;\x)-\ell'_n(\theta^*;\x)}{\theta-\theta^*}=\ell''_n(\tilde{\theta};\x)$$
for some $\tilde{\theta}\in(\theta,\theta^*)$. Hence, we deduce that
\[\begin{array}{rcl}
\ell'_n(\theta;\x)-\ell_n'(\theta^*;\x)&=&(\theta-\theta^*)\ell''_n(\tilde{\theta};\x)\\
&=&(\theta-\theta^*)\{\ell''_n(\theta^*;\x)+[\ell''_n(\tilde{\theta};\x)-\ell_n(\theta^*;\x)]\}\\
&=&(\theta-\theta^*)\{\ell''_n(\theta;\x)+R_n(\theta,\theta^*,\x)\}
\end{array}\]
Now we replace $\theta$ with the maximum likelihood estimator $\hat{\theta}_n:=\hat{\theta}_n(\X)$. We find
$$\ell'(\hat{\theta}_n;\X)=\ell'_n(\theta^*;\X)+(\hat{\theta}_n-\theta^*)\{\ell''_n(\theta^*;\X)+R_n(\hat{\theta}_n,\theta^*,\x\}$$
and we need to analyse $R_n$.\\
Since $\hat{\theta}_n\to_{\prob(\cdot;\theta^*)}\theta^*$ we can take $n$ large enough that $\prob(\hat{\theta}_n\in\Xi;\theta^*)$ with arbitrarily high probability.\\
On the event $\{\hat{\theta}\in\Xi\}$ and we have $\{\tilde{\theta}_n\in\Xi\}$ since $\tilde{\theta}_n\in(\hat{\theta}_n,\theta^*)$ and
\[\begin{array}{rcl}
|\frac{1}{n}R_n|&=&\frac{1}{n}|\ell''_n(\tilde{\theta}_n;\X)-\ell_n''(\theta^*;\X)|\\
&=&\dfrac{1}{n}\left|\sum\limits_{i=1}^n\ell''(\tilde{\theta}_n;X_i)-\ell''(\theta^*;X_i)\right|\\
&\leq&\dfrac{1}{n}\sum\limits_{i=1}^n\left|\ell''(\tilde{\theta}_n;X_i)-\ell''(\theta^*;X_i)\right|\\
&\leq&\Delta(\tilde{\theta}_n-\theta^*)\left\{\dfrac{1}{n}\sum\limits_{i=1}^nC(X_i)\right\}
\end{array}\]
from the smoothness condition on $\ell''$.\\
From the \textit{Weak Law of Large Numbers}
$$\frac{1}{n}\sum_{i=1}^nC(X_i)\to_{\prob(\cdot;\theta^*)}\expect(C(X_1);\theta^*)<\infty$$
and from the consistency of $\{\hat{\theta}_n\}$ and $\{\tilde{\theta}_n\}$ and continuity of $\Delta(\cdot)$ we have by the \textit{Continuous Mapping Theorem}
$$\Delta(\tilde{\theta}_n-\theta^*)\to_{\prob(\cdot;\theta^*)}0$$
Hence, $\frac{1}{n}R_n\to_{\prob(\cdot;\theta^*)}0\hfill\square$

\subsubsection{Confidence Intervals}

\theorem{Convergence in Distirbution of Confidence Intervals}
Let $\X\sim f(\cdot;\theta^*)$ with $\theta\in\Theta$ and define $\{\hat\theta_n\}_{n\in\nats}$ be a consistent sequence of estimators of $\theta^*$.\\
Suppose that $\{\hat\theta_n\}$ is asymptotically normal in the sense that
$$\exists\ \sigma^2>0\text{ st }\frac{\hat{\theta}_n(\X)-\theta^*}{\sqrt{\sigma^2/n}}\to_{\mathcal{D}(\cdot;\theta^*)}Z\sim\text{Normal}(0,1)$$
Then
\begin{center}$\forall\ \alpha\in(0,1),\ \mathcal{I}_n(\X)-[L_n(\X),U_n(\X)]$ is an asymptotically exact $1-\alpha$ condifence interval\end{center}
where $L_n(\x):=\hat{\theta}_n(\x)-z_{\alpha/2}\sqrt{\frac{\sigma^2}{n}}$ and $U_n(\x):=\hat{\theta}(\x)+z_{\alpha/2}\sqrt{\frac{\sigma^2}{n}}$.\\

\proof{Theorem 2.13}
Let $\{W_n\}_{n\in\nats}$ be defined by $W_n:=\frac{\hat{\theta}_n(X)-\theta^*}{\sqrt{\sigma^2/n}}$.\\
Since $W_n\to_{\mathcal{D}(\cdot;\theta^*)}Z\sim\text{Normal}(0,1)$ we have
\[\begin{array}{rcl}
\prob(-z_{\alpha/2}\leq W_n\leq z_{\alpha/2})&=&F_{W_n}(z_{\alpha/2})-F_{W_n}(-z_{\alpha/2})\\
&\underset{n\to\infty}{\longrightarrow}&\Phi(z_{\alpha/2})-\Phi(-z_{\alpha/2})\\
&=&1-\alpha
\end{array}\]
Similary to before we have the equivalence of events
$$\{-z_{\alpha/2}\leq W_n\leq z_{\alpha/2}\}=\left\{\hat{\theta}_n-z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\leq\theta^*\leq\hat{\theta}_n+z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\right\}$$
So $\lim_{n\to\infty}\prob\left(\hat{\theta}_n(X)-z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\leq\theta^*\leq\hat{\theta}_n(X)+z_{\alpha/2}\frac{\sigma}{\sqrt{n}};\theta^*\right)=1-\alpha$.$\hfill\square$


\subsection{Efficiency of Estimators}

\definition{Efficient Estimator}
Let $\hat\theta$ be an estimator of parameter $\theta$.\\
$\hat\theta$ is said to be an \textit{Efficient Estimator} if its variance is equal to the \textit{Craner-Rao Lower Bound} $\forall\ \theta^*$.
$$\forall\ \theta^*,\ \var(\hat\theta;\theta^*)=\frac{m'(\theta^*)^2}{nI(\theta)}$$

\definition{Asymptotically Efficient Sequence of Estimators}
Let $\X\sim f(\cdot;\theta)$ for $\theta\in\Theta$ and $\{\hat\theta_n(\X)\}_{n\in\nats}$  be a sequence of estimators.\\
The sequence $\{\hat\theta_n\}$ is \textit{Asumptotically Efficient} if either
\begin{enumerate}
	\item its \textit{Mean-Squared Error} converges in value to the \textit{Cramer-Rao Lower Bound}
	$$\forall\ \theta\in\Theta,\ n\text{MSE}(\hat\theta_n(\X_n);\theta)\underset{n\to\infty}{\longrightarrow}\frac{1}{I(\theta)}$$
	\item Or, $\hat\theta_n$ \textit{Converges in Distribution} to a standard Normal
	$$\forall\ \theta\in\Theta,\ \sqrt{nI(\theta)}(\hat\theta-\theta)\to_{\mathcal{D}(\cdot;\theta)}Z\sim\text{Normal}(0,1)$$
\end{enumerate}

\remarkk{Under the conditions of \textbf{Theorem 2.11} Maximum Likelihood Estimators are Asymptotically Efficient}

\section{Testing}

\subsection{Hypothesis Testing}
% Significance, Power

\definition{Hypothesis}
A \textit{Hypothesis} is a statement about the value of one or more parameters in a parameteric model.
$$H:\theta\in\Theta_0\text{ where }\Theta_0\subseteq\Theta$$

\definition{Simple Hypothesis}
A \textit{Simple Hypothesis} is a \textit{Hypothesis} which states that $\theta$ has an exact value.\\
\ie $H:\theta\in\Theta_0$ where $|\Theta_0|=1$.\\

\definition{Composite Hypothesis}
A \textit{Composite Hypothesis} is a \textit{Hypothesis} which states that $\theta$ takes one of a range of values.\\
\ie $H:\theta\in\Theta_0$ where $|\Theta_0|>1$.\\

\definition{Hypothesis Testing}
\textit{Hypothesis Testing} is the process using observed data to determine which of two \textit{hypotheses} is more consistent with the data.\\
For the \textit{hypotheses} we define a \textit{Null Hypothesis}, $H_0:\theta\in\Theta_0$, which is our default position \& an \textit{Alternative Hypothesis}, $H_1:\theta\in\Theta_1$ where $\Theta_1:=\Theta\backslash\Theta_0$.\\

\proposition{Hypothesis Testing Process}
Let $\x$ be a realisation of $\X$.
\begin{enumerate}
	\item Define a \textit{Model} $f(\dot;\theta)$, for $\theta\in\Theta$, st $\X\sim f(\cdot;\theta)$.
	\item Define a \textit{Null Hypothesis}, $H_0$, and an \textit{Alternative Hypothesis}, $H_1$.
	\item Define a \textit{Test Statistic}, $T(\cdot)$.
	\item Choose a \textit{Significan Level}, $\alpha$, and calculate the resulting \textit{Critical Value}, $c$.
	\item Calculate the observed value of the \textit{Test Statistic}, $t=T(\x)$.
	\item If $t\geq c$ then reject $H_0$ in favour of $H_1$, otherwise accept $H_0$.
\end{enumerate}

\definition{One-Sided Hypothesis Test}
Consider the two hypotheses $H_0:\theta\in\Theta_0\ \&\ H_1:\theta\in\Theta_1$.\\
A \textit{Hypothesis Test} on these two hypotheses is said to be a \textit{One-Sided Hypothesis Test} if both $\Theta_0\ \&\ \Theta_1$ are continuous regions of the parameter space.\\
\ie $\exists\ \theta_0\in\Theta$ st $H_0:\theta\leq\theta_0$ and $H_1:\theta>\theta_0$ (visa-versa) are equivalent definitions to above.\\

\definition{Two-Sided Hypothesis Test}
Consider the two hypotheses $H_0:\theta\in\Theta_0\ \&\ H_1:\theta\in\Theta_1$.\\
A \textit{Hypothesis Test} on these two hypotheses is said to be a \textit{Two-Sided Hypothesis Test} if at least one of $\Theta_0\ \&\ \Theta_1$ is not a continuous region of the parameter space.\\
\ie $\exists\ \theta_0,\theta_1\in\Theta$ st $H_0:\theta\in[\theta_0,\theta_1]$ and $H_1:\theta\not\in[\theta_0,\theta_1]$ (visa-versa) are equivalent definitions to above.\\

\definition{Type I \& Type II Error}
Consider the table below
\begin{center}
\begin{tabular}{|c|cc|}
\hline
Truth$\backslash$Action&\textbf{Retain $H_0$}&\textbf{Reject $H_0$}\\
\hline
\textbf{$H_0$ is True}&Correct&\textit{Type I Error}\\
\textbf{$H_1$ is True}&\textit{Type II Error}&Correct\\
\hline
\end{tabular}
\end{center}
\ \textit{Type I Error} occurs when the \textit{Null Hypothesis} is \underline{rejected}, when in fact it is \underline{true}.\\
\textit{Type II Error} occurs when the \textit{Null Hypothesis} is \underline{accepted}, when in fact it is \underline{false}.\\

\definition{Significance Level}
\textit{Signifiance Level}, $\alpha$, is the rate at which we allow \textit{Type I Errors} to occur
$$\alpha:=\prob(\text{Type I Error})\in[0,1]$$
\ie What is an acceptable proportion of times to reject $H_0$ when it is in fact true.\\
\nb Typically $\alpha\leq0.05$.\\

\remark{Significance Level is directly related to the phrase "Statistical Significance"}

\definition{Test Statistic}
A \textit{Test Statistic} is a random variable, $T$, whose value depends on the observed data set and is used to determime the outcome of a hypothesis test. \textit{Test Statistics} are defined in such a way that they measure how likely a given observation is given a particular hypothesis. Thus is an obseravation is deemed sufficiently unlikely my a \textit{Test Statistic} then we reject that hypothesis, in favour of the alternative.\\
\nb $T:\mathcal{X}^n\to\reals$ where $n$ is the number of observed values.\\

\propositionn{Common Test Statistics}
\begin{center}
\begin{tabular}{|l|l|}
\hline
\textbf{Test Statistic}&\textbf{Use}\\
\hline
${\displaystyle T(\x)=\frac{1}{n}\sum_{i=1}^nx_i\sim\text{Normal}\left(\mu,\frac{\sigma^2}{n}\right)}$&Testing mean\\
\hline
\end{tabular}
\end{center}

\definition{Equivalent Statistics}
Let $T(\cdot)\ \&\ T'(\cdot)$ be \textit{Test Statistics} and $\X$ be a \textit{Random Variable}.\\
We say $T(\cdot)$ and $T'(\cdot)$ are \textit{Equivalent Statistics} if
$$\forall\ c\in\reals\ \exists\ c'\in\reals\text{ st }\{\x\in\mathcal{X}^n:T(\x)\geq c\}\equiv\{\x\in\mathcal{X}^n:T'(\x)\geq c'\}$$

\proposition{Verifying Equivalent Statistics}
Let $T(\cdot)\ \&\ T'(\cdot)$ be \textit{Test Statistics}.\\
To verify that $T(\cdot)$ and $T'(\cdot)$ are \textit{Equivalent Statistics} it is sufficient to factorise $T(\cdot)$ as
$$T(\x)=Mf(T'(\x))$$
for some $M,f$ where $M$ is independent of $\x$ and $f(\cdot)$ is an increasing, bijective function.\\

\prooff{Proposition 3.3}
\[\begin{array}{rcl}
T(\x)\geq c&\Longleftrightarrow&Mf(T'(\x))\geq c\\
&\Longleftrightarrow&f(T'(\x))\geq\dfrac{c}{M}\\
&\Longleftrightarrow&T'(\x)\geq\underbrace{f^{-1}\left(\dfrac{c}{M}\right)}_{c'}
\end{array}\]

\definition{Critical Value}
A \textit{Critical Value}, $c\in\reals$, is an explicit value which if the observed value of the test statistic, $T(\x)$, exceeds then we reject the \textit{Null-Hypothesis}.\\
\ie If $T(\x;H_0)\geq c$ then we reject $H_0$.\\
\nb The \textit{Critical Value} depends on the \textit{Test Statistic} \& the \textit{Significance Level} used in a given test.\\

\definition{Critical Region}
The \textit{Critical Region}, $R$, is the set of observations which would lead to us rejecting the \textit{Null-Hypothesis}.\\
Let $T(\cdot)$ be a \textit{Test Statistic} \& $c$ be a \textit{Critical Value} then
$$R:=\{\x\in\mathcal{X}^n:T(\x)\geq c\}$$
\nb $\mathcal{X}^n=R\cup R^c$.\\

\definition{Power Function}
The \textit{Power Function}, $\pi(\cdot)$ measures the probability of rejecting the \textit{Null-Hypothesis} given that the true value of the parameter is $\theta$.\\
Let $\X\sim f(\cdot;\theta^*)$, $T(\cdot)$ be a test statistic, $c$ be a \textit{Critical Value} \& $R$ be the \textit{Critical Region}. Then
$$\pi(\theta;T,c):=\prob(\X\in R;\theta^*=\theta)=\prob(T(\X)\geq c;\theta^*=\theta)$$
\nb $\pi(\cdot;T,c):\Theta\to[0,1]$.\\

\remark{$\pi(\cdot;T,c)\equiv 1-\prob(\text{Type II Error})$}

\definition{Uniformly Most Powerful Test}
Define two \textit{Composite Hypotheses}, $H_0:\theta\in\Theta_0\ \&\ H_1:\theta\not\in\Theta_0$ for $|\Theta_0|>1$ and a \textit{Test}, $(T,c)$, for these hypotheses.\\
We say that this \textit{Test}, $(T,c)$, is a \textit{Uniformly Most Powerful Test} for these hypotheses if
$$\forall\ (T',c'),\ \pi(\theta;T,c)\geq\pi(\theta;T',c')\text{ for }\theta\in\Theta_1:=\Theta\backslash\Theta_0$$
\nb We refer to $T$ in this case as the \textit{Uniformly Most Powerful \underline{Test Statistic}}.\\

\remark{A Uniformly Most Powerful Test is not Guaranteed to exist}

\propositionn{Procedure for Hypothesis Testing with Composite Hypotheses}
\begin{enumerate}
	\item Calculate the \textit{Likelihood Ratio Test Statistic}, $T_{NP}(\cdot)$.
	\item Find the simplist \textit{Equivalent} test statistic, $T(\cdot)$, to the \textit{Likelihood Ratio Test Statistic}.
	\item Compute the \textit{$p$-Value} using the distribution of $T(\cdot)$ under the \textit{Null-Hypothesis}
	\item Determine whether you accept the \textit{Null-Hypothesis} given the computed \textit{$p$-Value}.
\end{enumerate}

\definition{$p$-Value}
The \textit{$p$-Value} of a \textit{Test Statistc} is the probability of observing a test statistic, $T(\X)$, at least as exteme as a realisation of the test statistic, $T(\x)$, under the \textit{Null Hypothesis}.\\
Let $\X\sim f_n(\cdot;\theta^*)$ be a \textit{Random Vector} for $\theta^*\in\Theta$, $\x$ be a realisation of $\X$, $T(\cdot)$ be a \textit{Test Statistic} and define a \textit{Null Hypothesis}, $H_0:\theta\in\Theta_0$.
$$p(\x):=\sup_{\theta_0\in\Theta_0}\prob(T(\X)\geq T(\x);\theta_0)$$
\nb $p(\x)$ is the smallest \textit{Significance Level} at which we would reject the \textit{Null Hypothesis}.\\

\remark{$p$-Value is a measure of the evidence against the Null-Hypothesis}

\definition{Size of a Test}
The \textit{Size of a Test} is the maximum power of a test under the \textit{Null-Hypothesis}.\\
Let $T(\cdot)$ be a \textit{Test Statistic} \& $c$ be a \textit{Critical Value}
$$\alpha:=\sup_{\theta\in\Theta_0}\pi(\theta;T,c)$$
\ie The greatest possible probability of making a \textit{Type I Error}

\subsubsection{Neyman-Pearson Approach}

\remark{Motivation}
TODO\\

\definition{Likelihood Ration Test Statistic}
Let $\x$ be a realisation of $\X\sim f_n(\cdot;\theta)$.\\
Consider two \textit{Simple Hypotheses} $H_0:\theta=\theta_0$ \& $H_1:\theta=\theta_1$.\\
The \textit{Likelihood Ratio Test Statistic} is
$$T_\text{NP}(\x):=\frac{L(\theta_1;\x)}{L(\theta_0;\x)}=\frac{f_n(\x;\theta_1)}{f_n(\x;\theta_0)}$$
\nb AKA \textit{Neyman-Pearson Test Statistic}.\\

\theorem{The Neyman-Pearson Lemma}
Let $\x$ be a realisation of $\X\sim f_n(\cdot;\theta)$.\\
Consider testing $H_0:\theta=\theta_0$ against $H_1:\theta=\theta_1$ using the \textit{Neyman-Pearson Test Statistic}, $T_\text{NP}$.\\
Let $c_\text{NP}$ be the \textit{Critical Value} st $(T_\text{NP},c_\text{NP})$ has \textit{Size} $\alpha$.
$$\ie\ c_\text{NP}\text{ st }\prob(T_\text{NP}\geq c_\text{NP};\theta_0)=\alpha$$
Then $(T_\text{NP},c_\text{NP})$ is \textit{Equivalent} to the \textit{Uniformly Most Powerful $\alpha$-Level Test}.\\

\proof{Theorem 3.1}
Consider for an arbitrary level $\alpha$ test $(T,c)$, the linear combination of \textit{Type I Errors} and \textit{Type II Errors}.
$$\phi(T,c):=c_{NP}\alpha(T,c)+\beta(T,c)$$
where $\alpha(T,c)=\prob(T(\X)\geq c;\theta_0)=\prob(\text{Type I Error})$ and\\ ${\beta(T,c)=\prob(T(\X)<c;\theta_1)=1-\prob(T(\X)\geq c;\theta_1)=\prob(\text{Type II Error})}$.\\
Then
\[\begin{array}{rcl}
\phi(T,c)&=&c_{NP}\alpha(T,c)+\beta(T,c)\\
&=&c_{NP}\prob(T(\X)\geq c;\theta_0)+[1-\prob(\X)\geq c;\theta_1)]\\
&=&{\displaystyle\left[c_{NP}\int\mathds{1}\{T(\x)\geq c\}f_n(\x;\theta_0)d\x\right]+\left[1-\int\mathds{1}\{T(\x)\geq c\}f_n(\x;\theta)d\x\right]}\\
&=&{\displaystyle1+\int\mathds{1}\{T(\x)\geq c\}\left[c_{NP}f_n(\x;\theta_0)-f_n(\x;\theta_1)\right]d\x}\\
&=&{\displaystyle 1+\int\mathds{1}\{T(\x)\geq c\}\left[c_{NP}-\dfrac{f_n(\x;\theta_1)}{f_n(\x;\theta_0)}\right]f_n(\x;\theta_0)d\x}\\
&=&{\displaystyle1+\int\mathds{1}\{T(\x)\geq c\}(c_{NP}-T_{NP}(\x))f_n(\x;\theta_0)d\x}
\end{array}\]
Now consider the difference
$$\phi(T,c)-\phi(T_{NP},c_{NP})=\int\big(\mathds{1}\{T(\x)\geq c\}-\mathds{1}\{T_{NP}(\x)\}\geq c_{NP}\}\big)(c_{NP}-T_{NP}(\x))f_n(\x;\theta_0)d\x$$
We observe that
$$\mathds{1}\{T_{NP}(\x)\geq c_{NP}\}=1\Longleftrightarrow c_{NP}-T_{NP}(\x)\leq0$$
and
$$\mathds{1}\{T_{NP}(\x)\geq c_{NP}\}=0\Longleftrightarrow c_{NP}-T_{NP}(\x)>0$$
Thus
$$\forall\ \x\in\mathcal{X}^n,\quad[\mathds{1}\{T(\x)\geq c\}-\mathds{1}\{T_{NP}(\x)\geq c_{NP}\}](c_{NP}-T_{NP}(\x))\geq 0$$
and hence as the integral of a non-negative function
$$\phi(T,c)-\phi(T_{NP},c_{NP})\geq0$$
We have established
\[\begin{array}{rcl}
0&\leq&\phi(T,c)-\phi(T_{NP},c_{NP})\\
&=&c_{NP}\alpha(T,c)+\beta(T,c)-c_{NP}\alpha(T_{NP},c_{NP})-\beta(T_{NP},c_{NP})\\
&=&\underbrace{c_{NP}}_{\geq0}[\alpha(T,c)-\alpha(T_{NP},c_{NP})]+\underbrace{\beta(T,c)-\beta(T_{NP},c_{NP})}_{\geq0}
\end{array}\]
Since $(T,c)$ specifies an $\alpha$-level test, we know $\alpha(T,c)\geq c$ while $(T_{NP},c_{NP})$ specifies an $\alpha$-size test so $\alpha(T_{NP},c_{NP})=\alpha$.\\
It follows that
$$\alpha(T,c)-\alpha(T_{NP},c_{NP})$$
so we have
$$\beta(T,c)-\beta(T_{NP},c_{NP})\geq0$$
which means $(T_{NP},c_{NP})$'s \textit{Type II Error} rate is no higher than $(T,c)$.\\
Since $(T,c)$ is an arbitrary $\alpha$ level test, we conclude that $(T_{NP},c_{NP})$ is the most powerful test with level $\alpha$.\proved\\

\remark{Neyman-Pearson Lemma with Non-Continuous Random Variables}
If $T(\X)$ is \underline{not} a continuous random variable, then it is possible that no $c_\text{NP}$ exists.\\
In this situation we perform an appropriate \textit{randomised} test, and this will also be the most powerful $\alpha$-size test.\\
\nb This is out of scope of this course.\\

\proposition{Neyman-Pearson Testing Procedure}
From \textbf{Theorem 3.1} we can deduce the \textit{Neyman-Pearson Testing Procedure} for testing two \textit{Simple Hypotheses}, $H_0$ against $H_1$.
\begin{enumerate}
	\item Use the \textit{Likelihood Ratio Test Statistic} as the \textit{Test Statistic}
	$$T_\text{NP}(\x):=\frac{L(\theta_1;\x)}{L(\theta_0;\x)}=\frac{f_n(\x;\theta_1)}{f_n(\x;\theta_0)}$$
	\item Find a critical value, $c$, st we achieve the desired significance level, $\alpha$.
	$$\alpha=\pi(\theta_0;T,c)=\prob(T_\text{NP}(\x)\geq c;\theta_0)$$
	\item Compute the \textit{Power} of the \textit{Alternative Hypothesis}
	$$\pi(\theta_1;T,c)=\prob(T_\text{NP}(\X)\geq c;\theta_1)$$
	\item Compute the observed test statistic, $t_\text{obs}:=T(\x)$ and report whether $T(\x)\geq c$.
	\item Report the power of the \textit{Alternative Hypothesis}, $\pi(\theta_1;T_\text{NP},c)$
\end{enumerate}

\remarkk{Limitations of Neyman-Pearson Approach to Hypothesis Testing}
\begin{enumerate}
	\item Reporting \textit{rejection/acceptance} of the \textit{Null-Hypothesis} does not show the strength of the evidence against the \textit{Null-Hypothesis}.
	\item We may wish to set the \textit{Significance Level}, $\alpha:=\pi(\theta_0)$, \& \textit{Type II Error Rate}, $\beta:=1-\pi(\theta_1)$ together, or optimise both to be as minimal as possible.
\end{enumerate}

\subsubsection{Generalised Hypothesis Testing}

\definition{Generalised Likelihood Ratio Test}
Let $\X\sim f_n(\cdot;\theta)$ be a \textit{Random Vector} and consider \textit{Composite Hypotheses} $H_0:\theta\in\Theta_0\ \&\ H_1:\theta\in\Theta_1$.\\
We define the \textit{Generalised Likelihhod Ratio Test} to be
$$\Lambda(\x):=\dfrac{\sup_{\theta\in\Theta_0}f_n(\x;\theta)}{\sup_{\theta\in\Theta}f_n(\x;\theta)}=\min\bigg\{\underbrace{1}_{\hat\theta\in\Theta_0},\underbrace{\dfrac{\sup_{\theta\in\Theta_0}f_n(\x;\theta)}{\sup_{\theta\in\Theta_1}f_n(\x;\theta)}}_{\hat\theta\not\in\Theta_0}\bigg\}$$
\nb This compares the best fit for the data under the \textit{Null Hypothesis} to the best fit from the whole parameter space.\\

\definition{Nested Parameter Space}
Assume the \textit{Parameter Space} is $\Theta\subseteq\reals^d$ for some $d\geq1$.\\
Define a continuously differentiable bijection, $\phi(\cdot):=(\phi_1(\cdot),\phi_2(\cdot)):\Theta\to\Phi_1\times\Phi_2$ where $\Phi_1\subseteq\reals^r\ \&\ \Phi_2\subseteq\reals^{d-r}$ for some $r\in\nats$.\\
$\Theta_0\subseteq\Theta$ is said to be \textit{Nested} in $\Theta$ if
$$\Theta_0:=\{\theta\in\Theta:\phi(\theta)=c\}\text{ for some }c\in\Phi_1\subseteq\reals^r$$
\nb $\text{dim}(\Theta_0)=d-r$.\\

\theorem{}
Let $\X\iid f(\cdot;\theta)$ be a \textit{Random Vector} for some $\theta\in\Theta_0$ where $\Theta_0$ is \textit{Nested} in $\Theta$.\\
Then
$$T_n(\X):=-2\ln\Lambda_n(\X)\to_{\mathcal{D}(\cdot;\theta)}W\sim\chi^2_r$$
where $r=\text{dim}(\Theta)-\text{dim}(\Theta_0)$.\\
\nb The proof of this relies on a Taylor Expansion of the Likelihood function.\\

\remark{The fact that $-2\ln\Lambda_n(\X)\to_{\mathcal{D}(\cdot;\theta)}W\sim\chi^2_r$, is a generalisation of the result which motivates Wilks Confidence Sets}

\propositionn{Computing an Approximate $p$-Value for Composite Hypothees}
\begin{enumerate}
	\item Compute \textit{Observed Test Statistic}, $T_n(\x):=-2\ln\Lambda_n(\x)$.
	\item Determine $r=\text{dim}(\Theta)-\text{dim}(\Theta_0)$.
	\item Compute the approximate \textit{$p$-Value}
	$$p(\x)=\prob(\chi^2_r\geq-2\ln\Lambda_n(\x))$$
\end{enumerate}

\subsection{Categorical Distribustions \& Pearson's $\chi^2$-Test}

\definition{Categorical Distributions}
Consider a scenario where a random variable $Y$ takes one of $m$ possible values, $\{1,\dots,m\}$ (\ie Categories) and $p_i:=\prob(Y=i)$. Then $Y$ is said to have a \textit{Categorical Distribution}
$$Y\sim\text{Categorical}(\textbf{p})$$
where $\textbf{p}$ is a vector of probabilities (\ie $\sum p_i=1$ \& $p_i\geq0\ \forall\ i$).\\

\definition{Counts in Categorical Distribution}
Let $\textbf{Y}\iid\text{Categorical}(\textbf{p})$ be $n$ random variables.\\

\definition{Multinomial Distribution}
Let $\textbf{Y}\iid\text{Categorical}(\textbf{p})$ be $n$ random variables and $\X:=\{N_1,\dots,N_m\}$, where ${N_k:=\sum_{i=1}^n\mathds{1}\{Y_i=k\}}$, represent the counts from $\textbf{Y}$.\\
Then $\X$ is said to have a \textit{Multinomial Distribution}
$$\X\sim\text{Multinomial}(n,\textbf{p})$$
with
\[\begin{array}{rcl}
f_n(\x;\textbf{p})&=&{\displaystyle\mathds{1}\left\{\sum_{i=1}^mx_i=n\right\}\left[\dfrac{n!}{\prod_{i=1}^mx_i!}\right]\prod_{i=1}^np_i^{x_i}}\\
\expect(N_i)&=&np_i\\
\var(N_i)&=&np_i(1-p_i)
\end{array}\]

\theorem{Maximum Likelihood Estimate - Multinomial Distribution}
Let $\X\sim\text{Multinomial}(n,\textbf{p}^*)$ \& $\x$ be a realisation of $\X$. Then
$$\hat{\textbf{p}}_\text{MLE}(\x)=(\hat{p}_1(\x),\dots,\hat{p}_m(\x))=\left(\frac{x_1}{n},\dots,\frac{x _m}{n}\right)$$

\proof{Theorem 3.3}
Note that
$$\sum_{i=1}^mp_i=1\implies p_m=1-\sum_{i=1}^{m-1}p_i$$
Hence there are only $m-1$ independent variables and
\[\begin{array}{rcl}
L(\textbf{p},\x)&=&L(p_1,\dots,p_{m-1};\x)\\
&\propto&{\displaystyle \prod_{j=1}^mp_j^{x_j}}\\
&=&{\displaystyle\left(\prod_{j=1}^{m-1}p_j^{x_j}\right)\left(1-\sum_{i=1}^{m-1}p_i\right)^{x_m}}
\end{array}\]
So
$$\ell(p_1,\dots,p_{m-1};\x)=C+\left(\sum_{i=1}^{m-1}x_j\ln p_j\right)+x_m\ln\left(1-\sum_{i=1}^{m-1}p_i\right)$$
Now for $k=1,\dots,m-1$.\\
\[\begin{array}{rrcl}
\text{Setting}&\frac{\partial}{\partial p_k}\ell(p_1,\dots,p_{m-1};\x)&=&\frac{x_k}{p_k}-\frac{x_m}{1-\sum_{i=1}^{m-1}p_i}\\
&&=&0\\
\implies&\frac{x_k}{p_k}&=&\frac{x_m}{p_m}\ \forall\ k\in[1,m]
\end{array}\]
So $\frac{x_1}{p_1}=\dots=\frac{x_m}{p_m}=c$ and $\sum_{i=1}^mp_i=1$.\\
$$\implies\sum_{i=1}^m\frac{x_i}{c}=1\implies\sum_{i=1}^mx_i=c\implies n=c$$
Hence $\frac{x_k}{p_k}=n\implies\hat{p}_j=\frac{x_k}{n}\ \forall\ k\in[1,m]$.\\
In order to confirm that this is a maximum we will show that $\ell(\textbf{p};\x)$ is concave.\\
\ie for $\lambda\in[0,1]\ \ell(\lambda \textbf{p}+(1-\alpha)\textbf{p}';\x)\geq\lambda\ell(\textbf{p};\x)+(1-\lambda)\ell(\textbf{p}';\x)$.
\[\begin{array}{rcl}
\ell(\lambda\textbf{p}+(1-\lambda)\textbf{p}';\x)&=&\sum_{i=1}^mx_i\ln(\lambda p_i+(1-\lambda)p_i')\\
&\geq&\sum_{i=1}^mx_i\left[\lambda_i\ln p_i + (1-\lambda)\ln p_i'\right]\text{ since $\ln x$ is concave}\\
&=&[\lambda\sum_{i=1}^mx_i\ln p_i]+x_i(1-\lambda)\ln p'_i\\
&=&\lambda\ell(\textbf{p};\x)+(1-\lambda)\ell(\textbf{p}';\x)
\end{array}\]
Thus concave.\\
It follows that
$$\Lambda_n(\x)=\frac{f_n(\x;\textbf{p}_0)}{\sup_{\textbf{p}\in\mathcal{S}_m}f_n(\x;\textbf{p})}=\prod_{i=1}^m\frac{p_{0,i}^{x_i}}{\hat{p}_i^{x_i}}=\prod_{i=1}^m\frac{p_{0,i}^{x_i}}{(x_i/n)^{x_i}}$$
so that
$$T_n(\x)=-2\ln\Lambda_n(\x)=-2\sum_{i=1}^mx_i\{\ln p_{0,i}-\ln(x_i/n)\}$$
is the \textit{Generalised Likelihood Ratio} test statistic. From the general theorem
$$T_n(\x)\to_{\mathcal{D}(\cdot;\textbf{p}_0)}\chi^2_{m-1}$$
since $\text{dim}(\mathcal{S}_m)=m-1$.\\
Many people rewrite this statistic as
\[\begin{array}{rcl}
T_n(\x)&=&{\displaystyle2\sum_{j=1}^mo_j\ln\left(\frac{0_j}{e_j}\right)}\\
&=&{\displaystyle2\sum_{j=1}^mn_j\ln\left(\frac{x_j/n}{p_{0,j}}\right)}\\
&=&{\displaystyle-2\sum_{j=1}^mn_j\ln\left(\frac{x_j}{np_{0,j}}\right)}
\end{array}\]
where $o_j=n_j$ is the observered number in category $j$ and $e_j=np_{0,j}$ is the expected number in category $j$.$\hfill\square$.\\

\definition{Pearson's $\chi^2$ Test Statistic}
Let $\X\sim\text{Categoritcal}(\textbf{p})$ where $\textbf{p}:=(p_0,\dots,p_m)$ and $\x$ is a relisation of $\X$.\\
We define \textit{Pearson's $\chi^2$ Test Statistic}  as
$$T_\text{Pearson}(\x):=\sum_{j=1}^m\frac{(x_j-np_{j})^2}{np_{j}}=\sum_{j=1}^m\frac{(o_j-e_j)^2}{e_j}\to_{\mathcal{D}(\cdot;\textbf{p})}\chi^2_{m-1}$$
where $o_j$ is the number of observations of category $j$ and $e_j$ is the expected number of observations of category $j$.\\
\nb TODO - something about degrees of freedom.

\section{Bayesian Inference}

\theorem{Bayes' Theorem}
Consider $X\sim f(\cdot;\theta)$.
$$\underbrace{p(\theta|X)}_\text{Posterior}=\dfrac{\overbrace{p(X|\theta)}^\text{Likelihood}\overbrace{p(\theta)}^\text{Prior}}{\underbrace{p(X)}_\text{Evidence}}$$

\definition{Prior Distribution, $p(\theta)$}
Consider random variable $X\sim f(\cdot;\theta)$.\\
A \textit{Prior Distribution} encodes our beliefs about the model parameters, $p(\theta)$, before any data is observed. Typically \textit{Priors} have less affect as the number of observed data points increases.\\

\definition{Posterior, $\prob(\theta|\X)$}
Consider random variable $X\sim f(\cdot;\theta)$ and let $\x$ be a set of realisations of $X$.\\
A \textit{Posterior Distribution} is used to learn possible values for the parameters of a model, given a set of observations from the model.\\

\definition{Conjugacy}
A \textit{Prior} is said to be \textit{Conjugate} if its distribution is in the same family as the \textit{Poseterior}. When a \textit{Prior} is \underline{not} \textit{Conjugate} one typically requires a computer to conduct \textit{Bayesian Inference}.\\

\proposition{Modelling Parameters}
Consider $X\sim f(\cdot;\theta)$.\\
Here we can consider $\theta$ to be a realisation of some random variable $\vartheta$ and theorise the distribution of $\vartheta$ in our \textit{Prior}.\\
\nb Often $\beta$-\textit{Distributions} are used, $\vartheta\sim\text{Beta}(\alpha,\beta)$. To set the values of $\alpha\ \&\ \beta$ we set the \textit{mean} \& \textit{variance} and then solve the resulting simultaneous equations.\\

\proposition{Generalisation of Posterior Distributions}
Consider \textit{Random Variable} $\X\sim f_n(\cdot;\theta)$ and $\X$ be a realisations of $X$.\\
Given a \textit{Prior Distribution}, $p(\theta)$, we can generalise the \textit{Posterior Distribution}
$$p(\theta|\x)=\dfrac{f_n(\x;\theta)p(\theta)}{\int_\Theta f_n(\x;\xi)p(\xi)d\xi}=\dfrac{L(\theta;\x)p(\theta)}{\int_\Theta L(\xi;\x)p(\xi)d\xi}\propto L(\theta;\x)p(\theta)$$
\nb This is equivalent to a \textit{Maximum Likelihood Estimate} from the \textit{Frequentist Approach}, but is a distribution rather than a point estimate.\\

\proposition{Making Estimations}
Given a \textit{Poseterior Distribution}, $p(\theta|\x)$, there are an infinite number of point estimates which could be used. Ones worth considering using are
\begin{enumerate}
	\item The \textit{Mean} of the \textit{Poseterior Distribution} (Common when the \textit{Posterior} is \textit{Unimodal}).
	$$\hat\theta=\int_\Theta\theta p(\theta|\x)d\theta$$
	\item The \textit{Maximum a Posteriori}. This might be misleading in certain situations.
	$$\hat\theta=\text{argmax}_{\theta\in\Theta}p(\theta|\x)$$
	\item The \textit{Median} of the \textit{Posterior Distribution} (Or other quantiles)
	$$p(\theta\geq\hat\theta)=0.5$$
	\item The \textit{Variance} of the \textit{Posterior Distribution} which depends on the model used.
	$$\hat\theta=\var(X)$$
\end{enumerate}

\definition{Posterior Expected Loss}
Consider a \textit{Random Vector} $\X\sim f_n(\cdot;\theta)$, $\x$ be a realisation of $\X$ \& $\hat\theta$ be an estimate of $\theta$.\\
Then the \textit{Posterior Expected Loss} of $\hat\theta$ is defined to be
$$R(\hat\theta|\x)=\int_\Theta L(\theta,\hat\theta)p(\theta|\x)d\theta$$
where $L(\theta,\hat\theta)$ is a non-negative \textit{Loss Function}.\\
\nb AKA \textit{Posterior Risk}.

\proposition{Loss Functions}
A \textit{Loss Function} is a measure of how much an estimate of a parameter deviates from the true value.\\
Some popular \textit{Loss Functions} are
\begin{center}\begin{tabular}{|l|l|l|}
\hline
\textbf{Name}&\textbf{Form}&\textbf{Bayes Estimate}\\
\hline
Squared Error Loss&$L(\theta,\hat\theta)=(\theta-\hat\theta)^2$&$\hat\theta_\text{Bayes}=\displaystyle\int_\Theta\theta p(\theta|\x)d\theta$  (Posterior Mean)\\
Absolute Value&$L(\theta,\hat\theta)=|\theta-\hat\theta|$&$\hat\theta_\text{Bayes}=\theta\text{ where }p(\theta|\x)=0.5$ (Posterior Median)\\
&$L(\theta,\hat\theta)=\mathds{1}(\theta\neq\hat\theta)$&$\hat\theta_\text{Bayes}=\text{argmax}_{\theta\in\Theta}p(\theta|\x)$ (Posterior Mode)\\
\hline
\end{tabular}\end{center}

\definition{Bayes Estimate}
Consider a \textit{Random Vector} $\X\sim f_n(\cdot;\theta)$ \& $\x$ be a realisation of $\X$.\\
A \textit{Bayes Estimate} of $\theta$ is 
$$\hat\theta_\text{Bayes}=\text{argmin}_{\theta\in\Theta}R(\hat\theta|\x)$$
\ie The value which minimise the \textit{Posterior Expected Loss}

\subsection{Credible Intervals}

\definition{Symmetric Credible Interval}
Consider a \textit{Random Variable} $\X\sim f_n(\cdot;\theta)$ and a realisation $\x$ of $\X$.\\
Let $\alpha\in[0,1]$.\\
An interval $(\theta_1,\theta_2)$, for $\theta_1,\theta_2\in\Theta$, is called a \textit{Symmetric $(1-\alpha)$ Credible Interval} if
$$\prob(\theta\in[\theta_1,\theta_2]|\x)=\int_{\theta_1}^{\theta_2}p(\theta|\x)d\theta=1-\alpha$$
\nb This is hard to generalise to the multidimensional scenario.\\

\definition{High Posterior Density Set}
Consider a \textit{Random Variable} $\X\sim f_n(\cdot;\theta)$ and a realisation $\x$ of $\X$.\\
Let $\alpha\in[0,1]$.\\
The $(1-\alpha)$ \textit{High Posterior Denisty} is the \textit{Level Set} defined as
$$\mathcal{HPD}_v:=\{\theta\in\Theta:p(\theta|\x)\geq v\}$$
where $v$ is chosen st
$$\prob(\theta\in\mathcal{HPD}_v|\x)=\int_{\mathcal{HPD}_v}p(\theta|\x)d\theta=1-\alpha$$
\nb These sets are difficult to compute \underline{without} a computer.\\

\theoremm{The $\mathcal{HPD}(1-\alpha)$ Credible Set is the smallest Subset of $\Theta$ containing exactly $1-\alpha$ of the total density/probability.}

\subsection{Bayesian Hypothesis Testing}

\remark{Difference to Frequentist Approach}
Consider a \textit{Random Variable} $\X\sim f_n(\cdot;\theta)$ where $\theta$ is a realisation of $\vartheta$ and ${\x\text{ is a realisation of }\X}$.\\
Consider testing the \textit{Composite Hypotheses}: $H_0:\theta\in\Theta_1,\ H_1:\theta\in\Theta_2$.\\
In the \textit{Bayesian Approach} we actually calculate
\[\begin{array}{rrcl}
&\prob(\vartheta\in\Theta_0|\X=\x)&=&\displaystyle\int_{\Theta_0}p(\theta|\x)d\theta\\
\text{and}&\prob(\vartheta\in\Theta_1|\X=\x)&=&\displaystyle\int_{\Theta_1}p(\theta|\x)d\theta
\end{array}\]

\example{Bayesian Hypothesis Testing}
Consider the testing the \textit{Simple Hypotheses} $H_0:\theta=\theta_0\text{ against }H_1:\theta=\theta_1$.\\
In a \textit{Bayesian} framework we can take into account the cost of making an error, and base our decision on the minimisation of this cost.\\
We construct a loss table
\begin{center}\begin{tabular}{|c|c|c|}
\hline
Truth $\backslash$ Decision&$\theta_0$&$\theta_1$\\
\hline
$\theta_0$&$L_{00}$&$L_{10}$\\
\hline
$\theta_1$&$L_{10}$&$L_{11}$\\
\hline
\end{tabular}\end{center}
$L_{ij}$ is the loss for choosing $H_i$ when actually $\theta=\theta_j$.\\
We assume $L_{ik}>L_{jj}$ for $i\neq j$ (\ie it is always more costly to make a wrong decision).\\
We aim to choose the hypothesis with the smallest \textit{Posterior Expected Cost}.\\
When we choose $H_0$ we \textit{risk} the following loss
$$R_0=L_{00}\times p(\theta_0|\x)+L_{01}\times p(\theta_1|\x)$$
and when we chosse $H_1$ we risk the loss
$$R_1=L_{10}\times p(\theta_0|\x)+L_{11}\times p(\theta_1|\x)$$
Hence we choose $H_1$ if $R_1<R_0$ (and visa-versa). \ie
\[\begin{array}{rrcl}
&L_{10}\times p(\theta_0|\x)+L_{11}\times p(\theta_1|\x)&<&L_{00}\times p(\theta_0|\x)+L_{01}\times p(\theta_1|\x)\\
\implies&p(\theta_0|\x)[L_{10}-L_{00}]&<&p(\theta_1|\x)[L_{01}-L_{11}]\\
\implies&\dfrac{p(\theta_1|\x)}{p(\theta_0|\x)}&>&\dfrac{L_{10}-L_{00}}{L_{01}-L_{11}}\\
\equiv&\dfrac{p(\x|\theta_1)p(\theta_1)}{p(\x|\theta_0)p(\theta_0)}&>&\dfrac{L_{10}-L_{00}}{L_{01}-L_{11}}\\
\implies&\dfrac{L(\theta_1;\x)}{L(\theta_0;\x)}&>&\dfrac{p(\theta_0)[L_{10}-L_{00}]}{p(\theta_1)[L_{11}-L_{11}]}
\end{array}\]
Note that is exactly the same form as the \textit{Neyman-Pearson Test}, expt that the \textit{"critical value"} is chosen according to our prior and our assessment of the risk of taking thw wrong decision.\\
In particular
\begin{enumerate}
	\item The greater the cost of a \textit{Type I Error}, $L_{10}$, the higher the threshold.
	\item The greater the cost of a \textit{Type II Error}, $L_{01}$, the lower the threshold.
	\item The greater the prior probability of $H_0$, $p(\theta_0)$, the higher the threshold.
	\item The greater the prior probability of $H_1$, $p(\theta_1)$, the lower the threshold.
\end{enumerate}

\newpage
\setcounter{section}{-1}
\section{Appendix}

\subsection{Notation}

\notation{Convergence}
$\{z_n\}_{n\in\nats}\to z$ denotes that the sequence of deterministic values $\{z_n\}_{n\in\nats}$ converges in \underline{value} to $z\in\reals$.\\
$\{Z_n\}_{n\in\nats}\to_\prob Z$ denotes that the sequence of random variables $\{Z_n\}_{n\in\nats}$ converges in \underline{probability} to random variable $Z$.\\
$\{Z_n\}_{n\in\nats}\to_{\prob(\cdot;\theta)} Z$ denotes that the sequence of random variables $\{Z_n\}_{n\in\nats}$ converges in \underline{probability} to random variable $Z$, dependent upon parameter $\theta$.\\
$\{Z_n\}_{n\in\nats}\to_\mathcal{D} Z$ denotes that the sequence of random variables $\{Z_n\}_{n\in\nats}$ converges in \underline{distribution} to random variable $Z$.\\

\notationn{Gamma Function}
$$\Gamma(x):=\int_0^\infty t^{x-1}e^{-t}dt$$

\subsection{Definitions}

\definition{Correlation}
LEt $X$ \& $Y$ be random variables.\\
\textit{Correlation} is a measure of dependence between two random variables
$$\text{Corr}(X,Y):=\frac{\cov(X,Y)}{\sqrt{\var(X)\var(Y)}}\in[-1,1]$$

\definition{Covariance}
\textit{Covariance} is a measures the joint variability of two random variables.\\
Consider random variable $X$ \& $Y$
$$\cov(X,Y)=\expect[(X-\expect(X))(Y-\expect(Y))]=\expect(XY)-\expect(X)\expect(Y)$$
If $X$ \& $Y$ are independent then $\cov(X,Y)=0$.\\
By definition of \textit{Covaraince} $\cov(X,X)=\var(X)$.\\

\definition{Estimation}
Let $\X\sim f_n(\cdot;\theta^*)$ with $\theta^*\in\Theta$ and $\x$ be a realisation of $\X$.\\
As \textit{Estimation} of model parameter $\theta^*$ is a statistic, $\hat\theta(\x)=T(\x)$, which is indtended to approximated the true value of $\theta^*$.\\
\nb Interchangeable with \textit{Estimate}.\\

\definition{Estimator}
Let $\X\sim f_n(\cdot;\theta^*)$ with $\theta^*\in\Theta$ and $\x$ be a realisation of $\X$.\\
An \textit{Estimator} of model paramter $\theta^*$ is the random variable $\hat\theta:=\hat\theta(\X)$ where $\hat\theta(\x)$ is an \textit{estimation} of $\theta^*$.\\

\definition{Expectation}
\textit{Expectation} is the mean value for a random variable.\\
Consider \textit{continuous} random variable $X$ with pdf $f_X$ and \textit{discrete} random variable $Y$ with pmf $f_Y$. Then
$$\expect(X):=\int_\reals xf_X(x)dx\quad\text{and}\quad\expect(Y):=\sum_{y\in\mathcal{Y}}yp_Y(y)$$
For a function $g:\reals\to\reals$ we have
$$\expect(g(X)):=\int_\reals g(x)f_X(x)dx\quad\text{and}\quad\expect(g(Y)):=\sum_{y\in\mathcal{Y}}g(y)p_Y(y)$$
For linear transformations of a random variable $Z$ we find
$$\expect(aZ+b)=a\expect(Z)+b\quad\text{for }a,b\in\reals$$

\definition{Five-Number Summary}
The \textit{Five-Number Summary} of a sample contains the sample's: median; lower hinge; upper hinge; minimum value; \& maximum value.\\

\definition{Hinges}
\textit{Hinges} describe the spread of data in a sample, while trying to ignore extreme data. The \textit{Lower Hinge}, $H_1$, is the median of the set containing the median \& values with rank \underline{less} than the sample median . The \textit{Upper Hinge}, $H_3$, is the median of the set containing the median \& values with rank \underline{greater} than the sample median.\\

\definition{Median}
The \textit{Median} is the central value of a data set.\\
Consider a data set $x_0,\dots,x_n$
\begin{itemize}
	\item[-] If $\exists\ m\in\nats\text{ st } n=2m+1$ (\ie $n$ is odd) then the median is $x_{(m+1)}$.
	\item[-] Else $\exists\ m\in\nats\text{ st } n=2m$ (\ie $n$ is even) then the median is $x_{(m+1)}$.
\end{itemize}

\definition{Moments}
The \textit{Moments} of a random variable $X$ are the expected values of powers of $X$.
$$n^{\text{th}}\text{ moment of }X:=\expect(X^n$$
\nb $\expect(X^n)\neq\expect(X)^n$.\\

\definition{Order Statistic}
An \textit{Order Statistic} is a data set where the data has been placed in increasing order of value, not time. We use $x_{(i)}$ to denote the $i^\text{th}$ lowest value in $(x_0,\dots,x_n)$.\\

\definition{Quartiles}
\textit{Quartiles} describe the spread of data in a sample.  The \textit{Lower Quartile}, $Q_1$, is the median of the set of values with rank \underline{less} than the sample median . The \textit{Upper Quartile}, $Q_3$, is the median of the set of values with rank \underline{greater} than the sample median.\\
\nb These sets do \underline{not} contain the median.\\

\definition{Sample Mean}
The \textit{Sample Mean} is the mean value of all data points within a sample. Consider a sample $\{x_1,\dots,x_n\}$
$$\bar{x}:=\frac{1}{n}\sum_{i=1}^nx_i$$

\definition{Sample Variance}
\textit{Sample Variance} is a measure of spread of data in a sample around the sample mean. For a sample $\{x_1,\dots,x_n\}$
$$s^2:=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2=\frac{1}{n-1}\left(\left(\sum_{i=1}^nx_i^2\right)-n\bar{x}^2\right)$$

\definition{Statistic}
Let $\x$ be some data.\\
A \textit{Statistic} is any function of the data, $T(\x)$.\\
\nb \textit{Statistics} are independent of unknown model parameters.\\

\definition{Trimmed Sample Mean}
The \textit{Trimmed Sample Mean} is the average value of a subset of data points within a sample. The subset is defined to ignore the $\frac{\Delta}{2}\%$ largest \& smallest values of the sample. For a $\Delta\%$ trimmed mean we define
$$\bar{x}_\Delta:=\frac{1}{n-2k}\sum_{i=k+1}^{n-k-1}x_i\ \mathrm{with}\ k=\left\lfloor\frac{n\Delta}{100}\right\rfloor$$

\definition{Variance}
\textit{Variance} measures how far a set of random numbers are spread from their average value.\\
Consider random variable $X$
$$\var(X):=\expect[(X-\expect(X))^2]=\expect(X^2)-\expect(X)^2$$
For linear transformation of a random variable $X$ we find
$$\var(aX+b(=a^2\var(X)$$
For a linear transformation of two random variables $X$ \& $Y$ we ahve
$$\var(aX+bY)=a^2\var(X)+b^2\var(Y)+2ab\cov(X,Y)\quad\text{for }a,b\in\reals$$

\definition{Skew}
\textit{Skew} describes the spread of values in a sample which are less than the median, relative to the spread of values greater than the median. A sample is \textit{Left-Skewed} if $|H_3-H_2|<|H_1-H_2|$. A sample is \textit{Right-Skewed} if $|H_3-H_2|>|H_1-H_2|$.\\

\subsection{Theorems}

\theorem{Cauchy-Scwarz Inequality}
Let $X$ \& $Y$ be real-valued random variables in the same probability space. Then
$$\expect(XY)^2\leq\expect(X^2)\expect(Y^2)$$

\theorem{Chebyshev's Inequality}
Let $X$ be a random variable.\\
Define $\mu:=\expect(X)$ and $\sigma^2:=\var(X)$. Then
$$\forall\ a>0\quad\prob(|X-\mu|\geq a)\leq\frac{\sigma^2}{a^2}$$

\theorem{Covariance Inequality}
Let $X$ \& $Y$ be real-valued random varaibles in teh same probability space. Then
$$\cov(X,Y)^2\leq\var(X)\var(Y)$$

\theorem{Joint Probability Density of Simple Random Sample}
Let $\X_1,\dots,X_n$ be a set of \underline{independent} random variables with pdfs $f_{X_1},\dots,f_{X_n}$, respectfully, and $x_1,\dots,x_n$ be a realisation of $X_1,\dots,X_n$.\\
The probability of obtaining $x_1,\dots,x_n$ is
$$f_{X_1,\dots,X_n}(x_1,\dots,x_n)=\prod_{i=1}^nf_{X_i}(x_i;\theta)$$

\theorem{Markov's Inequality}
Let $X\sim f_X(\cdot)$ be a non-negative continuous random variable. Then
$$\forall\ a>0\quad\prob(X\geq a)\leq\frac{\expect(X)}{a}$$

\subsection{Probability Distributions}

\definition{$\beta$-Distribution}
Let $X\sim\text{Beta}(\alpha,\beta)$.\\
A \textit{continuous} random variable with shape parameters $\alpha,\beta>0$. Then
\[\begin{array}{rcl}
f_X(x)&\propto&x^{\alpha-1}(1-x)^{\beta-1}\mathds{1}\{x\in[0,1]\}\\
\expect(X)&=&\dfrac{\alpha}{\alpha+\beta}\\
\var(X)&=&\dfrac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\\
\mathcal{M}_X(t)&=&1+{\displaystyle\sum_{k=1}^\infty\left(\prod_{r=0}^{k-1}\dfrac{\alpha+r}{\alpha+\beta+r}\right)\dfrac{t^k}{k!}}
\end{array}\]

\definition{Bernoulli Distribution}
Let $X\sim\text{Bernoulli}(p)$.\\
A \textit{discrete} random variable which takes 1 with probability $p$ \& 0 with probability $(1-p)$. Then
\[\begin{array}{rcl}
p_X(k)&=&\begin{cases}1-p&\text{if }k=0\\p&\text{if }k=1\\0&\text{otherwise}\end{cases}\\
P_X(k)&=&\begin{cases}0&\text{if }k<0\\1-p&\text{if }k\in[0,1)\\1&\text{otherwise}\end{cases}\\
\expect(X)&=&p\\
\var(X)&=&p(1-p)\\
\mathcal{M}_X(t)&=&(1-p)+pe^t
\end{array}\]
\nb Often we define $q:=1-p$ for simplicity.\\

\definition{Binomial Distribution}
Let $X\sim\text{Binomial}(n,p)$.\\
A \textit{discrete} random variable modelled by a \textit{Binomial Distribution} on $n$ independent events and rate of success $p$.\\
\[\begin{array}{rcl}
p_X(k)&=&{n\choose k}p^k(1-p)^{n-k}\\
P_X(k)&=&\sum_{i=1}^k{n\choose i}p^i(1-p)^{n-i}\\
\expect(X)&=&np\\
\var(X)&=&np(1-p)\\
\mathcal{M}_X(t)&=&[(1-p)+pe^t]^n
\end{array}\]
\nb If $Y:=\sum_{i=1}^nX_i$ where $\X\iid\text{Bernoulli}(p)$ then $Y\sim\text{Binomial}(n,p)$.\\

\definition{Categorical Distribution}
Let $X\sim\text{Categorical}(\textbf{p})$.\\
A \textit{discrete} random varaible where probability vector $\textbf{p}$ for a set of events $\{1,\dots,m\}$.\\
\[\begin{array}{rcl}
f_X(i)=p_i
\end{array}\]

\definition{$\chi^2$ Distribution}
Let $X\sim\chi^2_r$.\\
A \textit{continuous} random variable modelled by the \textit{$\chi^2$ Distribution} with $r$ degrees of freedom. Then
\[\begin{array}{rcl}
f_X(x)&=&\dfrac{1}{2^{r/2}\Gamma(r/2)}x^{\frac{r}{2}-1}e^{-\frac{x}{2}}\\
F_X(x)&=&\dfrac{1}{\Gamma(k/2)}\gamma\left(\frac{r}{2},\frac{x}{2}\right)\\
\expect(X)&=&r\\
\var(X)&=&2r\\
\mathcal{M}_X(t)&=&\indicator\{t<\frac{1}{2}\}(1-2t)^{-\frac{r}{2}}
\end{array}\]
\nb If $Y:=\sum_{i=1}^kZ_i^2$ with $\textbf{Z}\iid\text{Normal}(0,1)$ then $Y\sim\chi^2_k$.\\

\definition{Exponential Distribution}
Let $X\sim\text{Exponential}(\lambda)$.\\
A \textit{continuous} random variable modelled by a \textit{Exponential Distribution} with rate-parameter $\lambda$. Then
\[\begin{array}{rcl}
f_X(x)&=&\indicator\{t\geq0\}.\lambda e^{-\lambda x}\\
F_X(x)&=&\indicator\{t\geq0\}.\left(1-e^{-\lambda x}\right)\\
\expect(X)&=&\dfrac{1}{\lambda}\\
\var(X)&=&\dfrac{1}{\lambda^2}\\
\mathcal{M}_X(t)&=&\indicator\{t<\lambda\}\dfrac{\lambda}{\lambda-t}
\end{array}\]
\nb Exponential Distribution is used to model the wait time between decays of a radioactive source.\\

\definition{Gamma Distribution}
Let $X\sim\Gamma(\alpha,\beta)$.\\
A \textit{continuous} random variable modelled by a \textit{Gamma Distribution} with shape parameter $\alpha>0$ \& rate parameter $\beta$. Then
\[\begin{array}{rcll}
f_X(x)&=&\dfrac{1}{\Gamma(\alpha)}\beta^\alpha x^{\alpha-1}e^{-\beta x}\\
F_X(x)&=&\dfrac{\Gamma(\alpha)}\gamma(\alpha,\beta x)\\
\expect(X)&=&\dfrac{\alpha}{\beta}\\
\var(X)&=&\dfrac{\alpha}{\beta^2}\\
\mathcal{M}_X(t)&=&\indicator\{t<\beta\}\left(1-\frac{t}{\beta}\right)^{-\alpha}
\end{array}\]
\nb There is an equivalent definition of a \textit{Gamma Distribution} in terms of a shape \& \underline{scale} parameter. The scale parameter is 1 over the rate parameter in this definition.\\

\definition{Multinomial Distribution}
Let $\X\sim\text{Multinomial}(n,\textbf{p})$.\\
A \textit{discrete} random varible which models $n$ events with probability vector $\textbf{p}$ for events $\{1,\dots,m\}$.\\
\[\begin{array}{rcl}
f_\X(\x)&=&{\displaystyle\mathds{1}\left\{\sum_{i=1}^mx_i\equiv m\right\}\frac{n!}{x_1!\cdot\dots\cdot x_n!}\prod_{i=1}^np_i^{x_i}}\\
\expect(X_i)&=&np_i\\
\var(X_i)&=&np_i(1-p_i)\\
\cov(X_i,x_j)&=&-np_ip_j\text{ for }i\neq j\\
\mathcal{M}_{X_i}(\theta_i)&=&\left(\displaystyle\sum_{i=1}^mp_ie^{\theta_i}\right)^n
\end{array}\]
\nb In a realisation $\x$ of $\X$, $x_i$ is the number of times event $i$ has occured.\\

\definition{Normal Distribution}
Let $X\sim\text{Normal}(\mu,\sigma^2)$.\\
A \textit{continuous} random variable  with mean $\mu$ \& variance $\sigma^2$.
\[\begin{array}{rcl}
f_X(x)&=&\dfrac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\\
F_X(x)&=&\dfrac{1}{\sqrt{2\pi\sigma^2}}\int\limits_{-\infty}^xe^{-\frac{(y-\mu)^2}{2\sigma^2}}dy\\
\expect(X)&=&\mu\\
\var(X)&=&\sigma^2\\
\mathcal{M}_X(\theta)&=&e^{\mu\theta+\sigma^2\theta^2(1/2)}
\end{array}\]

\definition{Pareto Distribution}
Let $X\sim\text{Pareto}(x_0,\theta)$.\\
A \textit{continuous} random variable modelled by a \textit{Pareto Distribution} with minimum value $x_0$ \& shape parameter $\alpha>0$. Then
\[\begin{array}{rcll}
f_X(x)&=&\dfrac{\alpha x_0^\alpha}{x^{\alpha+1}}\\
F_X(x)&=&1-\left(\dfrac{x_0}{x}\right)^\alpha\\
\expect(X)&=&\begin{cases}\infty&\alpha\leq1\\\dfrac{\alpha x_0}{\alpha-1}&\alpha>1\end{cases}\\
\var(X)&=&\begin{cases}\infty&\alpha\leq2\\\dfrac{x_0^2\alpha}{(\alpha-1)^2(\alpha-2)}&\alpha>2\end{cases}\\
\mathcal{M}_X(t)&=&\indicator\{t<0\}\alpha(-x_0t)^\alpha\Gamma(-\alpha,-x_0t)
\end{array}\]

\definition{Poisson Distribution}
Let $X\sim\text{Poisson}(\lambda)$.\\
A \textit{discrete} random variable modelled by a \textit{Poisson Distribution} with rate parameter $\lambda$. Then
\[\begin{array}{rcll}
p_X(k)&=&\dfrac{e^{-\lambda}\lambda^k}{k!}&\text{for }k\in\nats_0\\
P_X(k)&=&{\displaystyle e^{-\lambda}\sum_{i=1}^k\frac{\lambda^i}{i!}}\\
\expect(X)&=&\lambda\\
\var(X)&=&\lambda\\
\mathcal{M}_X(t)&=&e^{\lambda(e^t-1)}
\end{array}\]
\nb Poisson Distribution is used to model the number of radioactive decays in a time period.\\

\definition{$t$-Distribution}
Let $X\sim t_r$.\\
A \textit{continuous} random variable with $r$ degrees of freedom. Then
\[\begin{array}{rcll}
f_X(k)&=&{\displaystyle\frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu\pi}\Gamma\left(\frac{\nu}{2}\right)}\left(1+\frac{x^2}{\nu}\right)^{-\frac{\nu+1}{2}}}\\
\expect(X)&=&\begin{cases}0&\text{if }\nu>1\\\text{undefined}&\text{otherwise}\end{cases}\\
\var(X)&=&\begin{cases}\frac{\nu}{\nu-2}&\text{if }\nu>2\\\infty&1<\nu\leq2\\\text{undefined}&\text{otherwise}\end{cases}\\
\mathcal{M}_X(t)&=&\text{undefined}
\end{array}\]
\nb Let $Y\sim\text{Normal}(0,1)\ \&\ Z\sim\chi^2_r$ be independent random variables then $X:=\dfrac{Y}{\sqrt{Z/r}}\sim t_r$.\\

\definition{Uniform Distribution - Uniform}
Let $X\sim\text{Uniform}(a,b)$.\\
A \textit{continuous} random variable with lower bound $a$ \& upper bound $b$. Then
\[\begin{array}{rcll}
f_X(x)&=&\begin{cases}\frac{1}{b-a}&x\in[a,b]\\0&\text{otherwise}\end{cases}\\
F_X(x)&=&\begin{cases}0&x<a\\\frac{x-a}{b-a}&x\in[a,b]\\1&\text{otherwise}\end{cases}\\
\expect(X)&=&\frac{1}{2}(a+b)\\
\var(X)&=&\frac{1}{12}(b-a)^2\\
\mathcal{M}_X(t)&=&\begin{cases}\dfrac{e^{tb}-e^{ta}}{t(b-a)}&t\neq0\\1&t=0\end{cases}
\end{array}\]

\subsection{Identities}

\subsubsection{Likelihood}

\proposition{Binomial}
Let $X\sim\text{Binomial}(n,p)$ with $n\ \&\ p$ unknown and $x$ be a realisation of $X$. Then
\[\begin{array}{rcl}
L(n,p;x)&\propto&{n\choose x}p^x(1-p)^{n-x}\\
\ell(n,p;\x)&=&\ln{n\choose x}+x\ln p+(n-x)\ln(1-p)+C\\
\hat{n}_\text{MLE}&=&\frac{x}{\hat{p}}\\
\hat{p}_\text{MLE}&=&\frac{x}{\hat{n}}\\
\end{array}\]

\proposition{Normal}
Let $\X\iid\text{Normal}(\mu,\sigma^2)$ with $\mu\ \&\ \sigma^2$ unknown and $\x$ be a realisation of $\X$. Then
\[\begin{array}{rcl}
L(\mu,\sigma^2;\x)&\propto&{\displaystyle(\sigma^2)^{-\frac{n}{2}}\text{exp}\left(-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\right)}\\
\ell(\mu,\sigma^2;\x)&=&{\displaystyle-n\ln\sigma^2-\frac{1}{\sigma^2}\sum_{i=1}^n(x_i-\mu)^2}+C\\
\hat{\mu}_\text{MLE}&=&\bar\x\\
\hat{\sigma}^2_\text{MLE}&=&{\displaystyle\frac{1}{n}\sum_{i=1}^n(x_i-\hat\mu)^2}\\
\end{array}\]

\proposition{Poisson}
Let $\X\iid\text{Poisson}(\lambda)$ with $\lambda$ unknown and $\x$ be a realisation of $\X$. Then
\[\begin{array}{rcl}
L(\lambda;\x)&\propto&e^{-\lambda n}\lambda^{n\bar{x}}\\
\ell(\lambda;\x)&=&-\lambda_n+n\bar{x}\ln\lambda+C\\
\hat\lambda_\text{MLE}&=&\bar{x}
\end{array}\]

\proposition{Uniform}
Let $\X\iid\text{Uniform}(a,b)$ with $a\ \&\ b$ unknown and $\x$ be a realisation of $\X$. Then
\[\begin{array}{rcl}
L(a,b;\x)&\propto&\begin{cases}\frac{1}{(b-a)^n}&a\leq\ x_i\leq b\ \forall\ x_i\in\x\\0&\text{otherwise}\end{cases}\\
\ell(a,b;\x)&=&\begin{cases}-\ln(b-a)&a\leq\ x_i\leq b\ \forall\ x_i\in\x\\0&\text{otherwise}\end{cases}\\
\hat{a}_\text{MLE}&=&\min\{x_i:x_i\in\x\}\\
\hat{b}_\text{MLE}&=&\max\{x_i:x_i\in\x\}
\end{array}\]

\end{document}
